
var tipuesearch = {"pages": [
     {
        "title": "Quick start guide",
        "text": "\nQuick Start Guide\nThis tutorial explains how to use the CLARIAH Media Suite. Before starting the tutorial, you may want to read this: What is the Media Suite?\nTo get started using the Media Suite, do the following:\n\nLog into the Media Suite\nCreate a \"user project\" in your Workspace\nFind relevant collections/data for your work\nInspect the metadata of the collections you are interested in\nSearch the collections/data for your research\nStore bookmarks in your \"user projects\"\nAnnotate your items\n\nSee also:\n\n\nQuick start guide to the Media Suite. Handout used at an introductory course to television history at Utrecht University (May, 2019)\n\n\nQuick start guide to the Media Suite with emphasis on the Collection Inspector. Handout used at the AVinDH workshop at DH2019.\n\n\n",
        "url": "/documentation/quick-start-guide"
    },
    {
        "title": "FAQ",
        "text": "\nFAQ\nWe collected answers to frequently asked questions in this FAQ. If you have further questions, please use our Fora for Support & Feedback.\n",
        "url": "/documentation/faq"
    },
    {
        "title": "What is the CLARIAH Media Suite?",
        "text": "\nWhat is the Media Suite?\nThe CLARIAH Media Suite is an application for doing research with data collections. It is meant to be used exclusively by scholars and students at universities and higher education (e.g., film, television, and other media scholars, oral historians, and political historians). They can log into the Media Suite using their university credentials. Others may also find the Media Suite useful however, such as employees of institutes that provide data collections. They receive access rights for their own collections. Or citizen scientists that may be interested in the open access collections that are available.\nThe CLARIAH Media Suite is one of the applications of the Dutch infrastructure for Digital Humanities and Social Sciences developed in the CLARIAH project. It facilitates access to key Dutch media collections with advanced multimedia search and analysis tools.\nThe Media Suite is an innovative digital research environment, an experimental environment (LAB), in which we are experimenting with new ways of working with multimedia data collections. It furthermore aims to cater to various levels of expertise and research interests: from providing access to many audiovisual collections for exploratory research to close reading; and from more complex modes of data analysis to distant reading strategies. The transparent search and analysis tools that the Media Suite offers, combined with its APIs that can be used with Jupyter notebooks, allow for many new possibilities for research and represents the middle ground between full algorithmic literacy and being a data novice. The Media Suite is in a constant process of co-development with its users and, in that sense, it is not a \u201cfinished\u201d environment. We regularly publish about this process and other aspects of the CLARIAH infrastructure and its Media Suite.\nBuilding blocks\n\nThe Media Suite can be decomposed into three building blocks: data, tools to work with the data, and a workspace to store your work with the data.\nData\nVia the CLARIAH infrastructure, the Media Suite provides access to data collections in Dutch archives (among others: The Netherlands Institute for Sound and Vision, EYE Film Museum collections, DANS oral history interview collections, collections from the Open Images Project). Typically, data collections are registered in a registry that allows the infastructure to either access collections directly or use some form of data harvesting to enables access.\nRead more on data here:\n\n\nWhat collections/data are available via the Media Suite?\n\n\nHow does the Media Suite make the data available?\n\n\nCan I play/view all the sources that I find via the Media Suite?\n\n\nTools\nAs a research environment, the CLARIAH Media Suite aims to support scholars in all the steps of their research process. At a general level, it provides tools for exploring the data and collections, creating personal selections (or corpora), adding annotations (such as tags, comments, links, and other metadata), and the possibility to export them. The Media Suite also facilitates working with data directly by using its APIs in combination with Jupyter Notebooks.\nWorkspace\nThe CLARIAH Media Suite offers a \u201cvirtual work space\u201d to its users. It allows researchers to store bookmarks, annotations, saved queries, personal collections, or automatic enrichments. The workspace thus provides researchers with novel ways for making transparent and managing their research process.\n",
        "url": "/documentation/faq/what-is-it"
    },
    {
        "title": "What kind of data is available via the Media Suite?",
        "text": "\nWhat data collection are made available?\nThe Media Suite aims to provide access to data collections at cultural heritage and knowledge institutions in The Netherlands. To access such collections, in the past scholars were typically required to visit the various institutions and work with the data in a reading room setting. With the Media Suite, scholars can stay behind their desktop and have online access to:\n\n\nan overview of potential interesting data sets in the Netherlands at various institutions in the Netherlands, including Netherlands Institute for Sound and Vision, Eye Film Institute, National Library, DANS, Meertens Institute and National Archive.\n\n\na set of tools to work with the data and to store personal work such as annotations, queries and private virtual collections.  \n\n\nMultimedia data\nThe Media Suite is geared towards working with multimedia data sets: audio, video, images and text. Individual collections are typically \"single media\" (of one media type, for example audio) but some collections are multimedia, such as Eye's Jean Desmet collection that has film (video), poster (images) and digitized papers (text). The Media Suite makes it possible to view and annotate each media type. We are developing several methods to do cross-media search and analysis, for example to research correlations between news reports on television (video) and in newspapers (text).\u00a0\nAccess restrictions\nWe bring tools to the data, because for reasons of copyright or privacy these data can not be brought to the tools by simply downloading them. Read here for more information on access restrictions.\nCollections in the Media Suite\nThe Media Suite aggregates metadata from audiovisual collections and related multi-media contextual sources that are maintained at cultural heritage and knowledge institutions in The Netherlands. For detailed information about the collections, see the Media Suite data registry.\n",
        "url": "/documentation/faq/what-data"
    },
    {
        "title": "How does the Media Suite make the data available?",
        "text": "\nHow does the Media Suite make the data available?\nTechnically, the integration of the metadata into the Media Suite is done either:\n\nBy using the APIs of the content providers (when available)\nBy harvesting the metadata exposed via the OAI-PMH protocol (when available), or,\nVia data dumps\n\nAccessing the media resources (videos, audio, images, text) works in a different way. In most cases, these objects are hosted by the contributing institutions or projects, and the Media Suite provides access to \"playout\" or \"viewing\" functionality either inside the Resource viewer, or by redirecting the users to the original provider (this is done, for example, in the case of the KB newspaper collection).\nSince one of the aims of CLARIAH is to encourage and support institutions to make their data available to researchers, in any of these cases, data provision is done in collaboration between CLARIAH and the contributing memory institutions or projects. Developers, scholars, and the curators from the institutions providing these data to be accessed via the CLARIAH Media Suite have been working together to make collections available via the Media Suite.\nFrom the technical perspective, the Media Suite works with documents expressed in JSON format. These documents are stored in Elastic Search (ES) indexes, which can be search and retrieved using Lucene (a free and open source information retrieval software library). The strengths of ES are the support to faceted search and full text retrieval.\nIn parallel, there is ongoing work in converting all collections available via the Media Suite to JSON-LD documents (linked open data). This is with the aim to facilitate future integration with ANANSI (see documentation section \"Registering data\"), the CLARIAH linked data central connection of all datasets. In version 3, the Media Suite offers only one experimental collection in JSON-LD (\"Open Images\" from The Netherlands Institute for Sound and Vision). This collection can be browsed using the Exploratory search tool. The \u201cmedia objects\u201d available in this way, are connected to the ES indexes, thus, users can seamlessly search and navigate this collection in both the ES-based Media Suite tools and the linked-data based exploratory tool. Future work (from September 2018 onwards) includes the conversion of the collections available in the Media Suite to linked open data.\n\u200b\n",
        "url": "/documentation/faq/how-data-is-made-available"
    },
    {
        "title": "Is the data enriched automatically?",
        "text": "\nIs the Media Suite's data enriched automatically?\nSome of the collections in the Media Suite have been enriched automatically, via Optical character recognition or by Automatic Speech Recognition.\nAutomatic Speech Recognition (ASR)\nASR is a process applied to recorded, digitized audio materials to convert the audio signal into a textual representation. In CLARIAH WP5, this process is being applied to the entire audio-visual collection of The Netherlands Insitute for Sound and Vision (NISV).\nFrom Version 3 (launched in July 2018), the textual outputs are made available for search and interactive navigation of the audio (radio and television) resources.\n\nThe Most complete, up-to date automatic speech recognition reports (and other statistics of the NISV collections) are available at the NISV collection statistics website.\n\nHere you will find dynamic and updated reports of the progress of ASR as it is being processed (e.g., as in the screenshot below). The numbers correspond to the entire collection of NISV, showing the amount of digitized items with a carrier and, from those, the amount of items that have ASR.\n\nNote:\n\nAt this moment, the timeline charts start in year zero. This will be fixed during spring 2019.\nIf you would like to use these graphs for a publication, you can use the direct link to the graph, zoom in to the timeline, and use the camera icon above the graph to download the result. Please don't forget to cite the chart properly by including:\nDescription of the image or title of the image (as it appears in each graphic's caption, or adding more detail if necessary to interpret the graphic)\nPublisher: The Netherlands Institute for Sound and Vision\nEditor: Mari Wigham and Willem Melder\nEdition or version (charts in this website are updated automatically, thus, the date of update is the same as the date of download/copy)\nAccess information (Website's URL and/or graphic URL)\n\nOther sources of information about ASR processing:\n\nOverview: in the release notes, per version, see Release notes Version 3. \nPaper on Speech Recognition and Scholarly research\nIn the Collection Inspector tool, adding the Audio-visual collection of Sound and Vision, and inspecting the fields with the label ASR (use the search box).\n\nOptical character recognition (OCR)\nThis type of automatic enrichment is available for these collections:\n\nThe Newspaper collection of the National Library of The Netherlands\nThe Desmet paper collection provided by the Eye Film Museum, enriched in collaboration with CREATE (University of Amsterdam)\n\n(Last update: April 4, 2019). If you have any questions, please contact us.\n",
        "url": "/documentation/faq/is-data-enriched"
    },
    {
        "title": "Who can access the Media Suite?",
        "text": "\nWho can access the Media Suite?\nOnly researchers that are working at secondary vocational-, higher education and research institutions in the Netherlands can log in using the employee account of their institution. The CLARIAH infrastructure can authenticate you using the SURF federated identity management service for secondary vocational-, higher education and research in the Netherlands that connects these institutions with CLARIAH. Here is a list of institutions (called \"IdP\" - Identity provider) that are part of this federation. Your organisation should be on the list if you want to log in as a researcher.\n\nThere is one exception to the rule that only researchers can log in and that is for collection owners. They can log into the Media Suite to access their own collections and help us with the maintenance and improvement of the data.\n\nWhy log in?\nIn order to be able to use all features of the CLARIAH Media Suite, you need to log in. After log in, you will be able to use the workspace to create projects, make annotations, store and share information. Also, you will be able to access data collections that are only available for researchers for reasons of copyright (only research use is permitted) or privacy (see our post on research data management).\n\nWithout logging in, you can still search and browse collections that have no copyright or privacy restrictions and are publicly available. However, you cannot use the 'scholarly features' such as creating projects and making annotations.  \n\nHow do we provide log in functionality?\nWhen you log in, this means that we can 'authenticate' you, we know who you are in the sense that we know that you are working at a secondary vocational-, higher education or research institution in the Netherlands. Or that you are an employee of an institute that provides data (collection owner). We don't know your name for example. Based on the 'authentication' we can now 'authorise' you to access collections that are not open access (for copyright or privacy reasons) and only available for research purposes. We currently follow a generic authorisation approach that provides access to all scholars. However, collections exists that require more detailed authorisation protocols, such as excluding students or authorisation for individual scholars. We are working on an authentication & authorisation mechanism that allows both generic and specific protocols.\nCLARIAH outsources authentication to SurfConnext, a service offered by SURF, an  ICT organisation for Dutch education and research. Students, teachers and researchers with an institutional account can log in to the Media Suite via SURFConext.\nLimited access to the Media Suite can occur when:\n\nWhen your institution does not appear in the SURFConext list: This happens when you are prompted to the login page of The Media Suite, you search for your institution in the search box, and your institution is not listed there. Most academic and research institutions in the Netherlands are connected with SURFConext. If your institution is not in the list, this means your institution is not connected. This issue has to be solved by the Dutch university or research institution to which the researcher belongs to. Your institution also has to connect to the CLARIN service (that the Media Suite belongs to), in the local SURFconext settings. If your institute is not listed in the Media Suite, you have to ask your local ICT helpdesk to make this connection. Every institution has one or more SURFcontext maintainers/responsibles who should be able to do this for you. To start, you can find information here: SURFconext wiki; and Surf Trust and Identity website.\nWhen you don't have a Dutch institutional affiliation: This happens when you find the institution in the SURFconext list, but you don't have valid credentials to log in. In Version 3, it is currently impossible to use the Media Suite without institutional credentials. We are working towards a  solution for this situation  in future versions.\nWhen a non-Dutch institution wants to have access to the Media Suite: This is impossible in Media Suite version 3. A possible solution may be to ask a Dutch host institution listed in the SURFConext institutions to create a temporary institutional account.\n\nUpdate April 5, 2019: in CLARIAH Plus we are working towards facilitating the authentication procedure  via CLARIN-EU, which means that all CLARIN member institutes in Europe will get access.\nSee also: How to log in\n",
        "url": "/documentation/faq/who-can-access"
    },
    {
        "title": "How do I cite the Media Suite in my research?",
        "text": "\nHow do I cite the Media Suite in my Research?\nIf you use the Media Suite in your research, please cite us using the version number of the Media Suite and a referrence to this paper: \n\nRoeland Ordelman, Liliana Melgar, Jasmijn Van Gorp, Julia Noordegraaf, Media Suite: Unlocking Audiovisual Archives for Mixed Media Scholarly Research, Selected papers from the CLARIN Annual Conference 2018, Pisa, 8-10 October 2018, Volume , Issue 159, 2019-05-28, Pages 133-143, ISSN 1650-3740 link\n\nHere you can find all publications related to the development of the Media Suite.\n",
        "url": "/documentation/faq/how-do-i-cite"
    },
    {
        "title": "Who are the users of the Media Suite?",
        "text": "\nWho are the users of the Media Suite?\nThe Media Suite is being developed together with media scholars and oral historians as part of the CLARIAH infrastructure project (See: Who develops the Media Suite?). It was intensively used and improved during the CLARIAH research pilot projects. It has also been was used at the CLARIAH summer school in 2018, where film, television, new media scholars, linguists, oral historians, sociologists and archivists, among others, used the Media Suite in real research projects.\nThe Media Suite aims to serve the needs of a wide variety of scholars (e.g., film, television, and other media scholars, oral historians, political historians) interested in cultural data and audiovisual heritage of Dutch history and society.\n\nLet us know in our Public forum if you have any suggestions to make the Media Suite support you better in your research!\n\nThese are some commens about the media suite by its users:\n\nYou can watch so much content just from home or office, amazing.\nhandy, very useful and helpful for researcher, makes me want to do research on so many things.\nI think all the functionalities are maturing, the user space, searching, ASR\nMore stable\nHaving access to large swathes of data that would be otherwise unavailable and benefitting from various tools to process it. \nLinking materials in the personal space \nThe visualizations of material next to each other. \nAccess to audiovisual material, ability to annotate.\nPrepared Notebook were great to work with\nASR (!), workspace (bookmarks, saving queries, sorting per project), intuitive interface\nThe best thing about the new version is the automatic speech recognition. The demonstration of this tool made me very curious and enthusiastic.\nThe ease with which records can be searched, using all kinds of data (including OCR'd!)\nEasy to navigate, great to search across sections, possibilities of checking the quality metadata, possibility to work in personal user space (and, in the future, share notes and annotation with other researchers), manuals and help sections. \nThe possibility to connect different kinds of records through annotations\n\nQueries could be stored and used in comparison. Search is quite fast. \n\n\nDesign (+)\n\nIts heading in the right direction!\n\n\u200b   \n(Last edit: March 7, 2019). If you have any questions, please contact us.\n",
        "url": "/documentation/faq/who-uses-it"
    },
    {
        "title": "Can I play/view all the sources that I find via the Media Suite?",
        "text": "\nCan I play/view all the sources that I find via the Media Suite?\nThe Media Suite provides access to data from different institutions (data providers), but does not host all the media resources (e.g., videos, images, documents). When you find a resource that is not viewable/playable this may be due to three reasons:\n\n\nThe resource has not been digitised yet: you can inspect the record\u2019s metadata, but not the actual  content. These cases are marked with a \u201cclosed eye\u201d icon in the result list of the Search tool. Look at the metadata in the Resource viewer to find out whether an item has actually been digitised. A way to solve this issue is to contact (or visit) the collection owner.\n\n\nThe resource is digitized, but the content provider prohibited  play-out  via the Media Suite (because, for example, of privacy or copyright restrictions). In Version 3, this scenario mostly applies to the DANS oral history collection.\n\n\nThe resource\u2019s content is  available, but requires additional authentication or access request. In Version 3, this case applies mostly to some collections from DANS.  You can use our Contact information, or the contact information pages of the data providers if you find issues in viewing the content. Please check before if this is not due to a common technical problem (see the Troubleshoting section).\n\n\nFor more information see FAQ: What kind of data is available via the Media Suite?\n",
        "url": "/documentation/faq/can-play-view"
    },
    {
        "title": "How does the Media Suite work?",
        "text": "\nHow does the CLARIAH Media Suite work?\n\nThe CLARIAH Media Suite is a \"virtual research environment\" (VRE) with a user-friendly interface plus more advanced services that provide direct access to the data via an API.\nThe tools for searching and browsing provide access to crucial Dutch audio-visual collections and available automatic enrichments, such as automatic speech recognition (ASR). The functionalities for bookmarking allow users to create their own corpus. The annotation tool enable further enrichment of the collection, and a Work space facilitates the viewing and basic exporting.\nIdeally, users start by creating a \"User project\", to which they can add bookmarks, annotations, queries, navigation paths, and tool sessions. This allows users to analyse sources in the Media Suite, and save their work. The Media Suite offers basic export features of the data available in the Work space, for example of project bookmarks and/or annotations.\nMore advanced users, who prefer working with the data via an API, can consult the Jupyter notebooks: these offer more flexibility to users who know Python. However, because most of the collections are protected by copyright or come with privacy restrictions, the use of the Jupyter notebooks also requires authentication.\n\n",
        "url": "/documentation/faq/how-it-works"
    },
    {
        "title": "How is the Media Suite being built?",
        "text": "\nHow is the CLARIAH Media Suite being built?\nThe overarching  aim of the CLARIAH Media Studies project is to build an environment that facilitates  access to audiovisual collections that are being made open for online research. CLARIAH supports  institutions with widening access to their collections, and provides state-of-the art tools for searching, analysing, enriching and combining data. From a methodological point of view, the Media Suite aims to translate  Unsworth\u2019s \"scholarly primitives\" (Unsworth, 2000) to a digital research environment, thereby offering a wide and diverse audience the means to to conduct research on digitised audiovisual collections.\nThe Media Suite functions as a  metadata aggregator in which  collections can be queried, enriched and\nmanipulated. User-friendliness and (meta)data transparency served as the guiding principles. Also, the Media Suite  hopes to trigger data and tool criticism.\nThe creation of the Media Suite followed a co-development approach: the interface was designed in continuous interaction with users. From the start, scholars have been actively involved in formulating the requirements, and prototyping (or testing) the interface. The CLARIAH project contained broadly two stages:\n\nIn the first stage (from 2015 to 2017), the software engineers and developers with the input from scholars in the CLARIAH team, created the foundations of the infrastructure. The initial functional and data requirements and inspiration came from prototypes created in previous projects: AVResearcherXL, Verteld Verleden, DIVE+, CoMERDa, and TROVe.\nIn the second phase, which started in April 2017, external scholars were involved as co-developers under the framework of the CLARIAH Research Pilot Projects.\nFrom 2018, the Media Suite continued to be further developed in the framework of CLARIAH Plus, focussing on supporting more advanced mixed-media and audio-visual analysis methods.\n\nMore information about how the Media Suite has been built is in our publications, added here. \n",
        "url": "/documentation/faq/how-is-built"
    },
    {
        "title": "Who develops the Media Suite?",
        "text": "\nWho develops the Media Suite?\nThe Media Suite is part of the CLARIAH infrastructure. The Media Suite is developed by The Netherlands Institute for Sound and Vision (NISV), which is one of the CLARIAH data centra.\nCoordination\n\nWork package/research coordination: Julia Noordegraaf (J.J.Noordegraaf@uva.nl)\nTechnical coordination and product manager at Netherlands Institute for Sound and Vision: Roeland Ordelman (rordelman@beeldengeluid.nl)\n\nDevelopment team at NISV\n\nJaap Blom\nWillem Melder\nMari Wigham \nJohannes Wassenaar\nJonathan Blok \nEduardo Navarrete \n\nRequirement analysts, documentation and dissemination\n\nLiliana Melgar (requirements analyst, researcher and tester)\nEva Baaren (liaison digital humanities, 2016-2018)\nTom Slootweg (2018-)\nIris van Vliet (2018)\nRosita Kiewik (2017)\n\nDevelopment researchers and collaborators\n\nMarijn Koolen (part of the development team between 2016-2017, currently developing together with NISV a scholarly web annotation client and leading the initiative for scholarly annotations interoperability)\nVictor de Boer (linked data senior researcher at VU and coordinator of linked data work in WP5)\nOana Inel (2017-2018)\nLora Aroyo (2016-2018)\nCarlos Mart\u00ednez Ortiz (collaborating software engineer from the Netherlands EScience Center, 2016-2018)\nWerner Helmich (developer at Frontwise, 2017)\nFrom September 2018 to February 2019, Hugo Huurdeman works on a project to improve the \"Resource viewer\"\nThe Media Suite is developed in alignment with CLARIAH WP2 (the work package responsible for the overall infrastructure coordination)\n\nScholars involved\n\nProfessor Julia Noordegraaf\nJasmijn van Gorp\nThomas Poell\nNorah Karrouche\nKaspar von Beelen\nBernhard Rieder \n\nScholars from the CLARIAH research pilot projects\n\nCrossEWT project: Susan Hoogervorst\nDream project: Toine Peters and Berrie van der Molen\nM&M project: Susan Aasman, Tom Slootweg, Rob Wegter, Vincent Ros\nMIMEHIST project: Christian Olesen, Kathleen Lodze\nNarDis project: Sabrina Sauer, Berber Hagedoorn\nReSpoNs project: Marcel Broersma, Frank Harbers, Mark Vallinga\n\n\nSee Also Wie is Wie / Who is Who in CLARIAH.\n\n(Last edit: January 31, 2019). If you have any questions, please contact us.\n",
        "url": "/documentation/faq/who-develops"
    },
    {
        "title": "Where is the Media Suite hosted?",
        "text": "\nWhere is the Media Suite hosted?\nThe Media Suite is hosted at the The Netherlands Institute for Sound and Vision (NISV), which currently acts as one of the CLARIAH centers. Not all content (media resources) are stored in this data centre though (see FAQ: Can I play/view all the sources that I find via the Media Suite?).\nAll tools and components developed within CLARIAH are open source, the Media Suite code is available on the CLARIAH GitHub repository page. \n(Last update: October 2, 2018) If you have any questions, please contact us.\n",
        "url": "/documentation/faq/where-is-hosted"
    },
    {
        "title": "Can I integrate data into the Media Suite?",
        "text": "\nCan I integrate data into the Media Suite?\nFor curators/data owners\nThe current instance of CKAN implemented for the CLARIAH Media Suite includes datasets that we have registered (by harvesting or importing them) on behalf of the collection owners. The Media Suite works as an \"aggregator\" of collections, which are incorporated in close collaboration with the contributing institutions and scholars. See FAQ: What kind of data is available via the Media Suite?\nIn the near future, more organisations can register their collections and add data themselves. Registration with an open licence is possible, but private access is also possible. The data itself can be added to each registered collection using different formats (e.g., XML, JSON, RDF).\n\nNote: CLARIAH also offers other data registration services (see Anansi information; Anansi video). Aligning these services is work in progress.\nFor questions or suggestions related to the Data services of the CLARIAH Media Suite, please use our Collections chat room in Gitter.\n\nNote: Institutions making available their collections via the Media Suite are responsible for creating and making full documentation of the metadata schemas available. A good practice is to provide metadata dictionaries.\nFor end-users\nNote: Registering your own personal datasets is not supported yet. But you can make your own \"User collections\" available via your Workspace.\n",
        "url": "/documentation/faq/can-register-data"
    },
    {
        "title": "What are the CLARIAH research pilot projects?",
        "text": "\nWhat are the CLARIAH Research Pilot projects?\nThe CLARIAH Research pilot projects was a grant scheme created by CLARIAH to involve researchers in the early stages of developing the Dutch Infrastructure. Six pilot projects were allocated to the Work package responsible for the Media Suite (WP5):\n\nCrossEWT (\"Cross-Medial Analysis of WW2 Eyewitness Testimonies\")\nDReAM (\"Cross media research of public debates on drugs and regulation\")\nM&M (\"Tracing first person in documentary history in AV-collections\")\nMIMEHIST (\"Annotating EYE\u2019s Jean Desmet Collection\", focused on making available the Jean Desmet collection for film historical research)\nNarDis (\"Narrativizing Disruption\", focused on exploratory search in the context of using linked open data)\nRespons (\"Remediation in Sports News\").\n\n(Last update: October 2, 2018) If you have any questions, please contact us.\n",
        "url": "/documentation/faq/what-are-research-pilots"
    },
    {
        "title": "HowTos",
        "text": "\nMedia Suite's HowTos\nHere you will find descriptions about how to accomplish specific tasks with the Media Suite. \nIf you have further questions, you can chat with us in the Gitter chat rooms, or use other ways to contact us). See also the Frequently Asked Questions or the Quick start guide.\n\nLog in\nFind and select collections\nInspect metadata quality\nUnderstand the metadata\nWork with user projects\nExplore and discover\nSearch\nBookmark\nSave queries\nCompare queries\nRead, view resources\nAnnotate\nConduct advanced analyses with Jupyter notebooks\nWork with your own collections (in progress)\n\nMore up to date information will be adding soon. If you have any questions, please contact us\n",
        "url": "/documentation/howtos"
    },
    {
        "title": "Access content",
        "text": "\nHow to access content\nSee FAQs: \n\nWhat collections/data are available via the Media Suite?\nCan I play/view all the sources that I find via the Media Suite?\n\nIf you have any questions, please contact us.\n",
        "url": "/documentation/howtos/access-content"
    },
    {
        "title": "Annotate",
        "text": "\nHow to Annotate\nBackground\nThe Media Suite annotation tool started to be built by reusing previous applications developed at The Netherlands Institute for Sound and Vision during projects such as LinkedTV, Axes, ArtTube, and lately the project The Mind of the Universe produced, among others, by the Dutch broadcaster VPRO. In the first project (LinkedTV), a strong emphasis was put on the automatic extraction of entities (e.g., names of persons, locations, buildings, etc.) from the spoken, written and visual message. Since this extraction could not fully rely on automatic means, a decision was taken to focus more on manual annotation and using automatically extracted information to aid the annotator (by displaying entity word clouds, or shot and scene thumbnails, or delete some of the automatically suggested links to web pages when these were unreliable). This tool was improved in the AXES project, where users were offered a way to annotate videos with the purpose of creating a \u201cground truth\u201d to be used in further evaluation of video hyperlinking. \nIn this way, the editing tools evolved into a manual annotation tool that has been \u201crebuilt\u201d within the CLARIAH Media Suite infrastructure. The tool is currently evolving to incorporate the most essential functionalities (i.e. segmenting, tagging, commenting, linking, and adding personal metadata via customizable templates) that were detected to be necessary in the aforementioned projects.\nYou can read more about this tool and how it has been used in scholarly research by one of the CLARIAH research pilot projects in:  Aasman, S., Melgar Estrada, L., Ros, V., Slotweg, T., & Wegter, R. (2018). Exploring Video Annotation for Doing Media History. VIEW Journal of European Television History and Culture, in print. \nHow to use\n\nSee at our CLARIAH YouTube channel the Screencast: \"Manual video annotation\", and \"Annotate\"\n\nThe control buttons are still under development, but the hotkeys allow you to create segments.\nEssential keyboard shortkuts:\n\ni (input key, start from a segment)\no (output key, end from a segment)\nSHIFT+s (save the segment as an annotation)\nSHIFT+e (open annotation tool in a pop-up)\nSHIFT+n (new segment)\n\nOther useful keyboard shortcuts (on test for Version 4):\n\nSHIFT + i (jump to the marked starting point)\nSHIFT + o (jump to the marked ending point)\nSHIFT + 1-9 (jump forward x seconds in the video)\nLeft arrow (jump 1 minute back in the video)\nRight arrow (jump 1 minute ahead in the video)\nCTRL+n (new segment from the end of the selected segment)\nSHIFT+rechts (select the next segment)\nSHIFT+links (select the previous segment)\nSHIFT+a (add new annotation to the resource (as a whole))\n\nNote: to assign a title to  your segment, use the \"metadata cards\", the title is set to use the value you enter in the \"metadata.title\" field. in the new version of the Resource viewer/Annotation tool, if you don't assign any value, the title will be generated by the comments/codes/links\n(Last update: July, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/annotate"
    },
    {
        "title": "Bookmark (create corpus)",
        "text": "\nHow to Bookmark\nBackground\nBased on the study of scholarly needs done in the requirement analysis phase of the CLARIAH Media Suite development, it was observed that, when browsing collections, scholars need to make selections of smaller \"corpora\" for closer investigation. To support this task, the Media Suite offers a bookmarking option.\nHow to use\n\nIn the Work space, start by creating your own User project\nIn the Search tool, make your query according to your wishes\nOnce you get a result list, use the icons on the left of the items to mark/unmark the items of your preference\nYou will get a dialog window inviting you to save your bookmarks to the user project that you created in the first step\nNote: there will be improvements in Version 4 allowing you to \"remember\" your selected items when changing pages in the search results\nAnother way to bookmark, individual items in this case, is via the Resource viewer, you will find a \"star\" icon in the viewer, and also the option to select the active User project in which you want to save your bookmark.\nTo see the resulting list of bookmarks, you can go to the Workspace and find them in the User project where you have saved them.\n\n(Last update: October 2, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/bookmark"
    },
    {
        "title": "Compare queries",
        "text": "\nTool: Compare\nThis tool facilitates comparative (re)search based on multiple queries on the same or different collections. The tool that inspired the creation of the \"Comparative\" functionality currently available in the Media Suite is AVResearcherXL. \nData\nThis tool uses all the data and enrichments available via the Media Suite. See Data page for more information.\nHow to use\nThere are two possible cases:\n\nIf you have saved queries via the Search tool, \nGo first to \"Set project.\" Here you can select your user project\nYou will se a list of your \"saved queries\" with their name and some details\nTick in the boxes next to the queries that you would like to compare\nThe graphic will show the aggregated results per query\nIf you have not saved queries before:\nClick on \"Add query\"\nYou will be prompted to the Search tool \nThere you can \"Save a query\" in a user project\nThen you are ready to use the Compare tool\n\n(Last update: November 5, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/query-comparison"
    },
    {
        "title": "Explore and discover (beta!)",
        "text": "\nTool: Explore\nThe Media Suite offers a tool for Exploratory search. This tool offers the possibility to explore and discover the Media Suite's collections in an open-ended way. \nBackground\nThis tool is the integrated version in the Media Suite of the tool DIVE+. See also the FAQ section: How has the Media Suit been built?\nLeading scholars from the CLARIAH research pilot project NarDis (see also the FAQ section: What are the CLARIAH research pilot projects? have investigated the use of this tool in humanities research, proposing the terms \"browsing path\" and \"search narrative\" to denote the storage of the \"journey\" followed by a user of the tool while navigating (\"diving\") into the interconnected resources and entities.\nData\nThis tool uses only one part of the data available via the Media Suite. Since working with linked open data in CLARIAH is an ongoing effort (see the FAQ section: How does the Media Suite make the data available?), the Media Suite offers in Version 4 (December 2018) only one experimental collection as linked open data, the Open Images collection from the Netherlands Institute for Sound and Vision\"[^1]. Only this collection can be accessed via the \"Browse and Explore\" tool at this point.\n[^1]: You can read more about this collection in the Media Suite's CKAN registration system\nHow to use\nSteps:\n\n\nFirst, log in to the Media Suite.\n\n\nIn the \"Tools\" menu, choose \"Explore.\" There are several links to access the DIVE+ instances, the version explained here is the tool you access in: http://mediasuite.clariah.nl/tool/exploratory-search.\n\n\nYou can start exploring by entering keywords into the search box, by choosing \"example searches\" under the search box, or by selecting \"popular entities\" or \"recent entities.\" \n\n\nObserve that the Explore tool allows you to search and browse based on \"entities\":\n\n\nYou can get information about the different types of \"entities\" that have been extracted from the original collections:\n\nMedia objects: these are the records of the resources (i.e., video, audio, text, image) which metadata and, in most cases, the objects itself, are available via the Media Suite. See also the FAQ section: Can I play/view all the sources that I find via the Media Suite?\nPeople: names of persons, which have been extracted or identified in the metadata or content of the resources\nLocations: names of places, which have been extracted or identified in the metadata or content of the resources.\nConcepts: terms representing ideas, which have been extracted or identified in the metadata or content of the resources.\n\n\n\nYou can also observe the types of relations (derived from the metadata) between the extracted entities:\n\nCreator of / created by\nHas subject / subject of\nPublisher of / published by\nLocated in / Location for\n\n\n\nYou can click on any entity of the type above, and start a navigation journey through the connected (linked-data) [[entities]]. This is led by the curiosity of the user, driven by the need to experience serendipitous encounters. In this fashion, exploratory search can lead to discovery of unexpected media resources or surprising connections between other entities\"[^1].\n\n\n[^1]: You can read more about these concepts in the publications of the NarDiS research pilot project\n\n\nObserve the \"Exploration path\" that appears on the left of your screen. When you click on an entity, you will see a panel opening on the left side. This panel stores your queries, entities, path bookmarks, and personal notes. This means that, every time you click on an entity in the middle panel browser, that entity is stored here. In the Exploration path panel you can:\n\n\nBookmark entities in this path (use the star icon on the right) \n\nNote: Please note that there are two bookmarking options: \n(1) the bookmark button in the browsing interface and in the \"Exploration path\": this bookmarks items and entities in your path (these items are not saved to your Workspace/Bookmarks, but to your \"Exploration path\" only. \n(2) the bookmark button that you see when you view a media object in the Resource viewer: If you bookmark the resources here, they will be saved to your Workspace/Bookmarks).\n\n\nAdd user comments or notes, by clicking on the three vertical dots on the left side of the bookmark icon. These comments are inserted between the entities, they allow you to add commentary to the path, so you can build a \"narrative\" of your exploration.\nYou can also clear your path, save it, load it, or export it. For these actions, click on the three vertical dots on the right side of the Exploration path menu:\nIf you \"Save\" your path, you get the option to save it to the Media Suite Workspace. If you click on this option, you will see a pop-up window asking you to select a User project. If you haven't created a User project, go first to the Workspace and create one.\nOnce you have saved your path, you can visit it in the Media Suite Workspace, going to the User project where you created it, to the tab \"Tool sessions.\"\nIn the Workspace, you can also find your bookmarks (in the \"Bookmarks\" tab), besides the fragments and annotations that you added to the media objects and fragments using the Resource viewer.\nYou can also \"Load\" (recreate) and \"Export\" your exploration path.\n\n\n\n(Last update: November 5, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/exploratory-search"
    },
    {
        "title": "Export",
        "text": "\nHow to export data\nVia the Workspace, you can export:\n\nYour user projects\nYour bookmarks\nYour annotations\n\nThe collections' metadata, and the content itself (media objects) cannot be exported or downloaded in all cases.\nThe resulting file from exporting the user data mentioned above is a JSON file.\n(Last update: July, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/export"
    },
    {
        "title": "Inspect metadata quality",
        "text": "\nTool: Inspect\nThis is a tool for the inspection of the metadata types in a collection, as well as for the evaluation of metadata quality of those fields. At this moment (Version 3), the Inspect tool offers the option to evaluate metadata completeness, which is calculated based on the number of records for which a given metadata field has been filled in. This completeness can be evaluated per field (all years), or along time. \nBackground\nThe \"collection inspection\" functionalities support the scholarly tasks of data criticism by facilitating the close inspection of the metadata fields that constitute each collection. \nThe purpose of this tool is to provide an overview of how a collection/dataset is constituted and also to allow a closer inspection of their metadata (e.g., detect incomplete data, or observe value distributions along date fields). \nIt is important to have clear that the collection inspector does not give search results. Future developments include the integration of other metrics (besides completeness) for the evaluation of metadata quality, and the possibility to visualize metadata completeness together with search results. \nHow to use\n\n\nWhen you open the Inspect tool you will find a button to add a Collection. This opens the \"Collection selector,\" where you can see the available collections (see FAQ section: What kind of data is available via the Media Suite?)\nWhen you select a collection, you can inspect its metadata fields by clicking on \"Select field to analyse\"\nIn this graphic you can see the completeness of ONE metadata field over time. The timeline chart uses a date field selected by the user. Be aware that these date fields are also metadata, and that they can also be more or less complete. You can evaluate the completeness of a date field as well, using the first option in Step 1.\nThere is a Jupyter notebook prepared for complementing the functions available in this tool. For example:\nIf you want to compare the completeness of two or more metadata fields\nIf you want to check the metadata completeness of a section of the collection (e.g., for resources of a certain media type)\n\n\nIf you are interested in the completeness of the ASR (automatic speech recognition transcripts) of the Netherlands Institute for Sound and Vision's audio-visual collection, visit this page.\n\nMetadata dictionaries\nBecause the Media Suite has been built following the principles of metadata transparency (which means that we only a minimum intervention in normalization and cleaning is done to the metadata provided by the institutions), users may face difficulties in understanding what a specific metada field means, or how to use it.\nIn Version 3, we provide an example of a good practice in documenting the metadata schemas for the users. This is done via \"metadata dictionaries,\" which provide definitions of the metadata field (regardless of their labels) when they are used in the Media Suite. \nWe have integrated this dictionary for one collection (The Netherlands Institute for Sound and Vision). The institution was responsible for creating a file with the technical label of the field plus a user-friendly label and a user-oriented definition of the field. These data was integrated into the Media Suite (you can observe it, for instance, when you click in the drop-down menu in the Inspector tool).\nThe CLARIAH WP5 team encourages other providing institutions to create and publish these metadata dictionaries as part of their metadata schemas and documentation.\n(Last update: November 5, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/collection-inspector"
    },
    {
        "title": "Log in",
        "text": "\nLogging into the CLARIAH Media Suite\nRead our post in the FAQ on logging into the Media Suite here for some background information.\nTo log in, follow these steps:\n\nGo to the Media Suite\nClick on the \"Log in\" button at the top right of the page\nIn the CLARIAH Digital Research Infrastructure interface, search for the name of your institution, or scroll through the list\nSelect your institution\nUse your institutional credentials to log in, wait until the service connects\nYou will arrive at the CLARIAH Media Suite workspace\n\n\nSee at our CLARIAH YouTube channel the Screencast: How to log in to the Media Suite\n\n\n\nTroubleshooting\nLimited access to the Media Suite can occur when:\n\nWhen your institution does not appear in the SURFConext list: This happens when you are prompted to the login page of The Media Suite, you search for your institution in the search box, and your institution is not listed there. Most academic and research institutions in the Netherlands are connected with SURFConext. If your institution is not in the list, this means your institution is not connected. This issue has to be solved by the Dutch university or research institution to which the researcher belongs to. Your institution also has to connect to the CLARIN service (that the Media Suite belongs to), in the local SURFconext settings. If your institute is not listed in the Media Suite, you have to ask your local ICT helpdesk to make this connection. Every institution has one or more SURFcontext maintainers/responsibles who should be able to do this for you.\nWhen you don't have a Dutch institutional affiliation: This happens when you find the institution in the SURFconext list, but you don't have valid credentials to log in. In Version 3, it is currently impossible to use the Media Suite without institutional credentials. We are working towards a  solution for this situation  in future versions.\nWhen a non-Dutch institution wants to have access to the Media Suite: This is impossible in Media Suite version 3. A possible solution may be to ask a Dutch host institution listed in the SURFConext institutions to create a temporary institutional account.\n\n",
        "url": "/documentation/howtos/login"
    },
    {
        "title": "Read, view, annotate",
        "text": "\nResource viewer\nThis is the \"Resource viewer.\" In this help pages you will learn how to:\nHow to use this tool (Screencast)\nPlay and view media\nUnderstand the metadata block\nUnderstand the \"all data\" block\nUsing the \"related content (experimental)\" block\nAnnotate resources and items\n How to use this tool\n(Forthcoming)\n Play and view media\n\nPlay and view the media resources that are available via the Media Suite (for more information about what resources can be viewed or played, read the FAQ section: Can I play/view all the sources that I find via the Media Suite?\nIf the resource has undergone the ASR process (see more information here), you will find an interactive transcript to navigate the audio or video file\n\n Understand the metadata block\n(forthcoming)\n Understand the \"all data\" block\n\nYou can also observe the full metadata, as imported from the contributing institution. \n\n(more information forthcoming)\n Using the \"related content (experimental)\" block\n(forthcoming)\n Annotate resources and items\n\nIn the Resource viewer you can also bookmark and add manual annotations to the media objects. You can do this for the entire media object or for your selected fragments\n\nThe control buttons are still under development, but the hotkeys allow you to create fragments. These are the essential keyboard shortkuts:\n\ni (input key, start from a segment)\no (output key, end from a segment)\nSHIFT+s (save the segment as an annotation)\nSHIFT+e (open annotation tool in a pop-up)\nSHIFT+n (new segment)\n\nYou can find more information about the annotation tool and other keyboard shorcuts here.\n(Last update: July, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/resource-viewer"
    },
    {
        "title": "Save queries",
        "text": "\nSave queries\nSee: How to compare queries. \nIf you have any questions, please contact us.\n",
        "url": "/documentation/howtos/save-queries"
    },
    {
        "title": "Search and select corpus",
        "text": "\nTool: Search\nIn this help menu you will learn How To:\n\nUse the Search tool (Screencast)\nKnow which data is used by the Search tool\nUse search expressions (Boolean operators)\nSearch layers (predetermined aggregations)\nSearch per field(s) (field cluster selector)\nFiltering per date\nUnderstand time line charts\nFilter using facets\nUnderstand how search results are ranked\nOrder your search results\nSave your query\nBookmark search results\n\n\nUse the Search tool\n\nKnow which data used by the Search tool\nThis tool uses all the data and enrichments available via the Media Suite. See Data page for more information.\nUse search expressions (Boolean operators)\nAt this moment (version 4) the search API detects when a user does a boolean/wildcard query by looking for the keywords: \nOR\n\nDefault operator. Connect two or more similar concepts (synonyms). ANY of your search terms can be present in the resulting records. Broaden your results.\n\nAND\n\nALL search terms must be present in the resulting records. Narrows your results\nExample: Koningin AND Beatrix\nSearches for the word \u2018Koningin\u2019 AND the word \u2018Beatrix\u2019 - but they do not have to be next to each other\n\nNOT\n\nIgnore concepts (words) that may be implied by your search terms\n\n*\n\nWildcard which matches any character sequence (including the empty one).\nExample 1: boeren --> boerenleven, boerenmarkt*\nExample 2: boeren *  --> boeren zijn bang\nNote that a space between the last character and the asterisk wildcard influences the results\n\n?\n\nWildcard which matches any single character\nExample 1: vluchteling? \u2014>  \u2018vluchtelinge\nSearches for a word that starts with \u2018vluchteling\u2019 and has one extra character\n\n\" \"\n\n\nExact expression\n\n\nExample 1: \"Broodje Aap\"\n\nSearches for the phrase Broodje Aap\n\nNesting and search order\n\n\nNesting queries is supported\n\n\nUse parentheses to separate the queries. The logical order in which words are connected influences the results\n\nExample1. (koe AND varkens) OR boeren \nExample2. Koningin AND Beatrix NOT \u201cKoningin Beatrix\u201d\nExample2 searches for items with the word \u2018Koningin\u2019 AND the word \u2018Beatrix\u2019 - but NOT the phrase \u2018Koningin Beatrix\u2019.  So we get e.g. items that talk about Prinses Beatrix and Koningin Juliana, but not Koningin Beatrix\n\nCapitalization\n\nBoolean queries are not case-sensitive\nExample: bordeaux, Bourdeaux \nSearching for any of these two terms will give the same results\n\nQuery corrections/suggestions\n\nThis is not supported\nExample: koningi\nSearching for this word gives no matches (matching is precise and does not accept typos or missing letters)\n\nNote: Future work includes supporting proximity parameters.\n Search layers\n\nTo facilitate more precise queries, users can use \"search layers,\" which are aggregations of metadata fields. At this moment (version 4) we support three layers for all collections:\n\nAll: searches in all the metadata and automatic enrichments at the time\nArchive's metadata: searches only in the mostly manually generated metadata (archival descriptions and subject/content metadata). These are the common aggregations for all collections:\nTitle field cluster: when there are different title fields, these have been aggregated and users can search in all of them at once\nDescription field cluster: searches in all fields (per each collection) which contain descriptions (e.g., summaries, abstracts)\nOther clusters: depending on the collection there may be other clusters available (e.g., \"Subtitles\" for the Sound and Vision audio-visual collection).\nEnrichments: searches in the existing layer(s) of mostly automatic content enrichments (e.g., OCR, or ASR- automatic speech transcripts)\n\nTip: To see which fields have been aggregated in each cluster, hover over the field cluster.\n Search per field (field cluster selector)\n\nUsers can determine in which field or group of fields they want to search for their query expression. For example, a user may want to search for a specific character's name (e.g., Mies Bouwman). In that case:\n\nUse the \"Custom field cluster\" button that appears in the drop-down menu of the Search layers (image above)\nSearch for the field of interest (e.g., \"cast\"). If there are many fields which include cast information, they can be aggregated in a \"field cluster.\" Assign a name to the cluster to create custom aggregations\nNow you can search in the cluster as if it was one of the Search layers described above.\n\nTip: To see the list of metadata fields per collection, as well as their definitions, use the Collection Inspector tool.\n Filtering per date\nYou can limit your query to a specific period of time. It is important to keep in mind that collections often include several fields of the type \"Date\". To see the metadata fields that are of the type \"Date\", you can use the \"Inspect\" tool and consult the metadata dictionaries.\n\nIn the date filter, you first have to select which date field you would like to use for filtering, and then enter the date range. For example, for The Sound and Vision audiovisual collection, we recommend to select the field \"Date:sorting (preferred)\" (which is the closest equivalent to the \"broadcasting date\"). You can check how complete this metadata field has been over time by using the Inspector tool.\n\nUnderstand time line charts\nThe timeline visualisation shows a histogram or a line chart with the amount of documents (relative or absolute) which match your query. \n\n\nTo generate a timeline visualization of your results based on time, first select a date field (see item before.\n\n\nMouse-overs show the year and the number of results per year.\n\n\nPlease note that the statistical unit (what is being counted) are documents (programs, articles, interviews), and not the number of occurrences of the term within a document; that is: \u201c1\u201d means one document (i.e., one television programme, one newspaper article, one oral history interview). \n\n\nThe relative frequencies (percentages) are calculated by dividing the number of documents with hits by the total number of documents within one year (or week, day, depending of the \u2018bucket\u2019).\n\n\nThis normalization helps to compare result numbers of different collections.\n\n\nPlease also note that each record possibly can have multiple occurrences of the selected date field (this happens clearly in the audio-visual collections of The Netherlands Institute for Sound and Vision, e.g., a rebroadcast), making it possible that there are more dates found that the number of search results. The number of cases can be seen in the \"Outside range\" summary in the chart panel:\n\n\n\n Filter using facets\n\n\nFaceted search: Facets include aggregations of terms from the metadata fields of the type \"Keyword field\", the terms included in each facet can be used for filtering the results of your query. To see the metadata fields that are of the type \"Keyword\", you can use the \"Inspect\" tool. At this moment (version 3) we support:\n\n\nDefault facets per collection: we include facets for the most important fields in each collection (e.g., \"Broadcaster\" for the Sound and Vision collection)\n\nCreation of new facets: users are allowed to add their own facets to the faceted search functionality (see screencast: Search)\n\n Understand how search results are ranked\n\n\nList of search results: The Search tool gives a list of search results after entering your query and filters. You can in this list:\n\n\nOrder results per relevance (description to be included soon)\n\n\nOrder results per date: it chooses the date field you used for filtering\n\n\nSee a summary of the metadata: using the \"document\" icon on the left\n\n\nSee information per item about:\n\nMedia type: there are icons on the right side of each item indicating whether it is of the type image, audio, video, or text\nAccess: if you can \"view\", \"play\", \"read\" a document, you will see an icon with an open eye on the right side of the item\n\n\n\nOrder your search results\n Save your query\n\nSave the query paramenters: the Search tool allows users to store the queries for further use giving them a name. See Saved queries section for more details.\n\n Bookmark search results\n\nBookmark items: the screencast below shows how the bookmarking functionality works. See also the Bookmarks section in the Documentation.\n\n\n\nPlease use our Public forum if you miss content in this page or if you find any issues while using the Media Suite.\n\n(Last update: March 7, 2019). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/single-search"
    },
    {
        "title": "Select collections",
        "text": "\nSelect collections\nTo get access to the data, please follow these steps:\nResearchers/end users of the Data services of the CLARIAH Media Suite:\n\n\nOpen CKAN by using the \"Visit CKAN\" button at the end of the Data page of the Media Suite. You will be redirected to an external service, the Media Suite instance in the CKAN registration software.\n\n\nIn that page, you can see the datasets that are registered (made available) in the Search and Inspect tools of the Media Suite. You can search registered datasets by using:\n\n\n-Tags (thematic, media types), \n-Organizations (creators of the datasets or collections), or \n-Groups (groups are used to organise datasets by data provider). \nNote: Please be aware that these tags, organizations and groups refer to the \"dataset level\", not to the content itself.\nIf you want to search (or view) the content of the datasets, go to the Tools section of the Media Suite. You will find a \"Collection selector\" in each tool, which will give you the list of available/registered collections that you can see in CKAN.\n(Last update: July, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/select-collections"
    },
    {
        "title": "Use the data",
        "text": "\nData\nHowTos of the Media Suite's data:\n\nHow to find data/collections\nHow to search and explore the data/collections\nInspect the metadata and their completeness\nHow to know which data has automatic enrichments (from version 3: automatic speech recognition (ASR) transcripts are available for a growing number of The Netherlands Institute for Sound and Vision collections)\n\nSee also the most frequently asked questions:\n\nWhat kind of data is available via the Media Suite? \nHow does the Media Suite make the data available?\nCan I play/view all the sources that I find via the Media Suite?\n\n(Last update: July, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/data"
    },
    {
        "title": "Use the tools",
        "text": "\nTools\nThe CLARIAH Media Suite's data can be explored, searched, bookmarked, and analysed (annotated) using the Media Suite's tools. These tools have been designed with the aim to support scholars in the main steps of their research process. \nRead more about the How-Tos of the Media Suite's data in our data documentation pages. Here you will find information about how to:\n\nInspect: inspecting the metadata fields per collection, checking their completeness in general and over time.\nExplore: browsing the available collections in a serendipitious fashion (Note: in Version 4, this tool integrates the available data only partially).\nSearch: dedicated tool for searching/exploring through a single collection.  faceted search for more structured querying of all the available collections. \nCompare: enables comparing the results from different saved queries created with the Search tool.\nIn the Explore and Search tools users can view and bookmark their own selections of media objects or fragments for their own personal selections (also called corpora). They can also annotate their personal corpora (by adding annotations such as tags, comments, links, and other metadata). These user-generated data and the users' personal collections are available in the Workspace, and can also be exported. The Media Suite also facilitates working with data directly by using its APIs in combination with Jupyter Notebooks\n\nSee also the most frequently asked questions:\n\nHow does the Media Suite work? \nHow is the Media Suite being built?\n\n(Last update: November 30, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/tools"
    },
    {
        "title": "Use the workspace",
        "text": "\nWorkspace\nThe Workspace is an experimental enviroment for users of the Media Suite to work with their personally created collections (bookmarks, annotations, queries), and to upload and enrich their own data.\n\n(Figure representing the Media Suite Workspace's services and elements)\n(Last update: November 5, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/workspace"
    },
    {
        "title": "Work with the Workspace's user projects",
        "text": "\nWorking with the Workspace\nTypically, researchers perform a variety of tasks in the Media Suite, such as formulating queries for searching collections, creating their own 'virtual collections', and making annotations. The Media Suite offers a \u201cvirtual Workspace\u201d to allow researchers to save their work. The workspace thus provides researchers with possibilities to manage their research process and enable transparancy of the process. \nThe Workspace supports the following functions:\n\n\nOrganising work in User Projects\n\n\nAdding personal collections to the Workspace to apply Media Suite functions such as search and annotation \n\n\nProgramming with data using Jupyter Notebooks (only limitedly available \n\n\nIn the Figure below, an overview of these functions is presented:\n\nUser Projects\nIn the Media Suite, a User project is defined as a container for storing personal corpora and annotations created during search and analysis of the data available in the Media Suite. Some of the Qualitative Data Analysis (QDA) typically used by researchers, refer to user projects as \"hermeneutic units\" (in Atlas.ti) or \"Projects\" (in NVIVO).\nIn the Media Suite, for instance, a researcher can create a user project for a topic or for a research question, which will help her/him, among others, to:\n\nGroup together entire items or fragments for creating a corpus (the so-called \"bookmarks\"),\nAdd and retrieve manual annotations\nStore and compare saved queries\nKeep track of her/his browsing history (the so-called \"navigation paths\" in the Exploratory tool) \nTake screenshots of \"tool sessions\" (in Version 4 only available in the Exploratory tool).\n\nIn the User Project page in the Workspace you see the list of your personal user projects (empty for first time users). You can:\n\nCreate a new user project.\nView the list of projects with their name, description, number of bookmarks (items in your corpus), project owner, privacy level (in version 3 all projects are \"private\" by default), your access rights (in version 3 the user is \"administrator\" for all projects created by her/him), and the creation date.\nOpen a user project, delete it, or export it.\n\n",
        "url": "/documentation/howtos/user-projects"
    },
    {
        "title": "Create",
        "text": "\nCreate user project\n(Documentation forthcoming)\nIf you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-projects/create"
    },
    {
        "title": "Edit",
        "text": "\nEdit user project\n(Documentation forthcoming)\n(Last update: July, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-projects/edit"
    },
    {
        "title": "See details",
        "text": "\nUser project details\nThe project details show basic information about your user project. In this section of the Workspace you can see the details of your user project.\nFrom now, you can start using the Media Suite tools, adding bookmarks, annotations, and queries.\n(Last update: July, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-projects/details"
    },
    {
        "title": "Work with your bookmarks",
        "text": "\nBookmarks\nBookmarks are your saved items or fragments, they constitute your \"corpus\".\nBookmarks are selections made by the users of the Media Suite. After querying the available collections, the items in the result list can be saved (e.g., television programs, films, letters, oral history interviews, newspaper articles, among others). The Media Suite supports users in making these selections, since we consider them important for corpus creation. Users can find these bookmarks in their Workspace, and order them (e.g., by creating \"bookmark groups\").\nThe metadata (not the items themselves) of the resulting bookmark lists can be searched, sorted, filtered, and exported using the Workspace functionalities.\n(Last update: July, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-projects/bookmarks"
    },
    {
        "title": "Work with your annotations",
        "text": "\nAnnotations\nAnnotations include \"codes\" (or tags), comments, links, and other metadata that you manually add to your bookmarked items.\nThe Media Suite supports scholars in bookmarking items or fragments (for creating a corpus), and in adding their own annotations. These annotations can be: \n\n\"Classifications\", which are short words, tags, or key terms (the so-called \"codes\" in qualitative analysis research). These codes can be added from external controlled vocabularies or thesauri provided by the Media Suite, or entered on the fly according to the user preferences. \nComments: these are natural language notes written by the scholar. They take the form of personal \"memos\" or \"commentaries\" intended to be shared or exported.\nLinks: users can add links to their items or fragments. These links can be external (for further reference), or internal (to other items or fragments in the Media Suite).\nMetadata cards: a very powerful feature of the annotation functionality is the possibility to add custom metadata templates (the properties are decided by the user), and values to those templates. These metadata can be used to describe the items or fragments more in detail, for further processing via the exporting facilities.\n\nIn Version 3 we support manual annotation only. Future versions will support automatic annotation (mainly for \"classification\" tasks), and will bring significant improvements in vocabulary and linking services.\n(Last update: July, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-projects/annotations"
    },
    {
        "title": "Work with your saved queries",
        "text": "\nSaved queries\nWhen using the Search tool of the Media Suite, users create queries using different search parameters (e.g., date filters). The Media Suite allows users to save these queries for further reference in their Workspace, and for comparing results using the Compare tool.\nThe query parameters stored are the following:\n\nSelected collection\nSearch expression (the search terms and Boolean operators)\nThe field cluster(s) used for the query (e.g., if the search was done in the titles, descriptions, subtitles, etc.)\nThe selected date field, and the date range (i.e., start date and end date)\nThe facet name and the facet terms used for filtering (e.g., Broadcaster: NOS) using the default facets\nThe facet name and the facet terms used for filtering (e.g., Colour: zwart/wit) using the user-added facets\nThe ordering option chosen for the search results (e.g., per date)\n\nHow to use\n\n\nSelect your User project\n\n\nUse the \"Save query\" button in the Search tool \n\n\n\n\nYou will be asked to store the query assigning it a name\n\n\n\nYou can find your stored query in the Workspace (going to the User project that you selected in the first step)\n\n\nYou can then either copy the parameters (e.g., to use it in a publication in which you would like to explain which query you used to get the data), or select the saved queries that you would like to compare (see how to use the Compare tool).\n(Last update: November 5, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-projects/queries"
    },
    {
        "title": "Work with your tool sessions",
        "text": "\nTool Sessions\nTool sessions are \"snapshots\" of the state in which a tool was when you saved your session.\nIn this section of the Workspace you can access your saved \"Tool sessions\". At this moment (Version 3), the Media Suite only supports the storage of tool sessions from the \"Explore/Browse\" tool. Users can also \"Save queries\" via the Search tool.\n(Last update: July, 2018). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-projects/tool-sessions"
    },
    {
        "title": "Work with User Collections",
        "text": "\nUser Collections\nThe User Collections are your own media files.\nNOTE: From version 3, the functionality for uploading users' own Youtube media to their Workspace user projects is available. But, this functionality is not fully working. This is because some back-end work with the playout of sources, which depends on the general CLARIAH infrastructure. The team is working on providing this service properly, and it will be available in the coming months (hopefully at the end of 2019 or beginning of 2020).\nWhen it is ready, this will be the basic functionality:\nUsers' \"personal collections\" can also be searched, bookmarked and annotated using the same functionalities that the Media Suite offers for other collections. \nSteps:\n\nCopy the Youtube URL of your audio/video item (this has to be publicly available)\nGo to the Media Suite's workspace, and click on \"User collections\"\n\n\n\n\nClick on \"Add User collection\"\n\n\nEnter the details of your collection\n\n\n\n\nClick on \"OPen\"\n\n\n\nClick on \"Add\" (to start adding items to your collection)\n\n\n\nEnter the details/metadata of your Youtube item\n\n\n\u200b                                       **Preferably use the \"Share\" URL given by Youtube\n\nNow you can Open the file in the Media Suite's Resource viewer, and use the annotation tool.\n\n(more documentation coming soon...)\n(Last update: October 23, 2019). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-collections"
    },
    {
        "title": "Create",
        "text": "\nUser Collection Create\n(Documentation forthcoming)\nIf you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-collections/create"
    },
    {
        "title": "Edit",
        "text": "\nUser Collection Edit\n(Documentation forthcoming)\nIf you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-collections/edit"
    },
    {
        "title": "Enrich",
        "text": "\nEnrich (ASR)\nNot available in Version 3. Forthcoming in Version 4.\nIf you have any questions, please contact us.\n",
        "url": "/documentation/howtos/user-collections/enrich"
    },
    {
        "title": "Work with the APIs in the Jupyter Notebooks",
        "text": "\nHow to use the Media Suite APIs with Jupyter Notebooks\nWe offer experimental Jupyter notebooks for those users who prefer working with the data directly using our APIs and their Python skills.\nThere are four notebooks available, in which we included common functions and code prepared by our experts:\n\nAn introduction to Jupyter Notebooks, to experiment with basic python coding\nTo inspect metadata completeness (giving more possibilities than those offered by the Inspector tool)\nTo inspect the availability of ASR data using different variables (program title, genre, etc.)\nA workspace notebook prepared for working with data fetched from the collections' metadata and ASR based on bookmarks and annotations added by the users to their workspace.\n\nIn its first phase of the Jupyter Notebooks service (launched with Version 3 in July, 2018), the notebooks are offered in an authenticated environment. \n\nTake me to the Media Suite's Jupyter notebooks. Requires VPN connection to The Netherlands Institute for Sound and Vision and a user account.\nRequest access to the Media Suite's Jupyter notebooks. You will need to fill in a form before access is granted.\n\nPlease use our contact details if you need more information.\nBesides, we produce Collection notebooks to create overviews of the Media Suite's collections composition. We use some of the visualizations produced with these notebooks to update our Collection pages in the Data registry CKAN. More complete documentation of the Collection notebooks can be found in the Github repository wiki.\nSee our publication about the Jupyter notebooks and the Media Suite.\n(Last update: March 18, 2019). If you have any questions, please contact us.\n",
        "url": "/documentation/howtos/jupyter-notebooks"
    },
    {
        "title": "Troubleshooting",
        "text": "\nTroubleshooting\nHere we list some reported problems by users of the Media Suite, and their solutions. If you find other problems or issues, please let us know.\nNote! Please keep in mind that the Media Suite is only tested in Google Chrome for now.\nPlayout not working\nPlease remember to read also the FAQ about which sources can be viewed/played via the Media Suite.\nThis happens if you are logged into the Media Suite and an audio-visual resource from the Sound and Vision collection is supposed to play, i.e., you get a player window, but the resource does not play, i.e., if you get something like this):\n\nThere are at least two ways to solve it:\nFirst solution\n\nIn Chrome, go to Settings (using the three dots on the right upper side)\nGo to Advanced \nContent settings\nCookies\nAnd deactivate \"Block third-party cookies\"\nNote that this would allow other sites to write cookies.\n\nSecond solution\n\nClick on the icon with the shape of a cookie where you get the message \"This page was prevented from setting cookies\" (see below):\n\n\n\n\nGo to \"Show cookies and other site data\"\n\n\nClick on \"Blocked\"\n\n\nClick on \"mediasuite.clariah.nl\"\n\n\nClick on the \"Allow\" button below, and \"done\"\n\n\nClick on \"Reload\"\n\n\nNow you should be able to play the audio or video. Otherwise, please Contact us.\n",
        "url": "/documentation/troubleshooting"
    },
    {
        "title": "Support & Feedback",
        "text": "\nMedia Suite Support & Discussions\nPublic Forum\nYou can contact the CLARIAH Media Suite team for:\n\n\nquestions you cannot find an answer to or problems you cannot solve (please read the documentation first)\n\n\nbug reports\n\n\ndiscussions on new features and future directions ;)\n\n\nNote that the forum uses Gitter, an open source instant messaging and chat room system. To start chatting, you would need to have either a Twitter or Github account. \nProject Forum\nThe Media Suite is developed with researchers for researchers in the CLARIAH Project, work package 5. For questions or remarks we share a project-internal Forum via the Project forum in Gitter.\n",
        "url": "/documentation/forum"
    },
    {
        "title": "Release notes",
        "text": "\nRelease notes\n\nVersion 4.14 (03-06-2020)\nVersion 4.12 (22-04-2020)\nVersion 4.11 (03-04-2020)\nVersion 4.10 (25-03-2020)\nVersion 4.9 (09-03-2020)\nVersion 4.7 (20-01-2020)\nVersion 4.4 (23-10-2019)\nVersion 4.3 (31-07-2019)\nVersion 4 (03-04-2019)\nVersion 3.2 (05-03-2019)\nVersion 3.1 (23-01-2019)\nVersion 3 (20-06-2018)\nVersion 2.1 (01-25-2018)\nVersion 2 (12-20-2017)\nVersion 1 (04-01-2017)\n\n",
        "url": "/documentation/release-notes"
    },
    {
        "title": "Version 4.14",
        "text": "\nRelease notes V4.14 (03-06-2020)\nThanks for using the CLARIAH Media Suite!\nEnhancements\n\nwe are always seeking balance between new features and squashing bugs. We fixed some bugs but we know there are still some on the list. We'll get to these ASAP. Please report issues here.\n\nData improvements\nFor this release we are proud to announce two major data upgrades:  \n\n\nThe Media Suite now also provides access to recent data from the \"DAAN\" archiving system of Netherlands Institute for Sound and Vision. Until now we could only provide data until 2018 based on the index of NISVs 'old' archiving system (\"iMMix\"). To ensure backward compatibility and smooth migration, the Media Suite will keep both data sets for some time. Note that we will be busy optimising the new collection the coming weeks, e.g., to improve speed. If you encounter issues, please report them here \n\n\nThe digitised TV and Radio Ratings (1966-1993), called \"Kijk- en Luistercijfers\" in Dutch, are now available for browsing in the Media Suite.\n\n\nStability improvements\n\nWe finished the set-up of automated tests to improve the stability of the Media Suite. We have integrated Screenster to enable us to do better UI testing as to increase the comfort of our users while working with the Media Suite.\n\nInfrastructure improvements\n\nWe worked on our Linked Data infrastructure and integrated with grlc.io that allow for a better organisation and management (and ultimately a more user-friendly use) of SPARQL queries.\n\nWork in progress\n\nWe are working on our second Data Story, this time on 'factual divergencies' regarding the coronavirus between Dutch official media channels and citizens on social media.\n\n",
        "url": "/documentation/release-notes/v4-14"
    },
    {
        "title": "Version 4.12",
        "text": "\nRelease notes V4.12 (23-04-2020)\nEnhancements\n\nBug fixes (such as problems with playback of content in Desmet collection)\n\nData improvements\n\nWe added the Viewer Ratings data information in our data registry.\n\nStability improvements\n\nWe are setting up automated tests to improve the stability of the Media Suite. We have integrated Screenster to enable us to do better UI testing as to increase the comfort of our users while working with the Media Suite.\n\nInfrastructure improvements\n\nWe have built a \"Distributed Annotation 'n' Enrichment\" (DANE) system that handles job assignment and file storage for the automatic annotation of content, for example using video analysis. To make DANE more portable and usable CLARIAH wide, we are making it possible to roll out the DANE stack automatically. It currently installs automatically on a CentOS VM.\n\nWork in progress\n\n\nTo enable access to recent NISV data we are working on connecting the latest version of the NISV catalogue to the Media Suite. We have been testing the connection with workspace API\n\n\nWe are preparing the digitized Viewer Ratings data (Kijk- en Luistercijfers) to be added as a collection for the Media Suite. The past weeks we have been configuring testing the indexing of the data. As there were still some errors we will be re-indexing the coming weeks.\n\n\nWe are working on preparing the data and infrastructure to make it possible to use Linked Data concepts within the Media Suite and the CLARIAH infrastructure. The past weeks we have been evaluating querying the NISV data using  properties related to the involvement of Persons (producer, creator, speaker etc.) and Places (recordingLocation, location etc.)\n\n\n",
        "url": "/documentation/release-notes/v4-12"
    },
    {
        "title": "Version 4.11",
        "text": "\nRelease notes V4.11 (03-04-2020)\nEnhancements\n\nSeveral bug fixes\nYou can now transfer queries you generated for one collection to the other collection as the search query box now remembers a query when you change collections.\nBug fixed that prevented users to browse through segments in the Resource Viewer\n\nWork in progress\n\nTo enable access to recent NISV data we are working on connecting the latest version of the NISV catalogue to the Media Suite. As this is a very large data set we are still busy with the process of ingesting, indexing and testing. This sprint we finished the new mappings\nWe are preparing the digitized viewing figures data (Kijk- en Luistercijfers) to be added as a collection for the Media Suite\nWe are working on enabling \"data stories\" based on data visualisations created using the Media Suite and experimented with possibilities to generate data for 15 years of DWDD.   \n\n",
        "url": "/documentation/release-notes/v4-11"
    },
    {
        "title": "Version 4.10",
        "text": "\nRelease notes V4.10 (25-03-2020)\nEnhancements\n\nSeveral bug fixes\nThe collection registry (CKAN) infrastructure reinstalled to increase stability. \n\nNew features\n\nYou can now use a bare bones version of the Media Suite without logging in for collections that are public domain such as Open Images, KB Newspaper collection (Via Delpher) and Soundbites. Use of the Workspace and features related to the Workspace (such as making annotations) are disabled.  \n\nData improvements\n\nIn view of the termination of the DWDD program, we added speech recognition for all DWDD broadcasts to facilitate even more deep dives into the past of the show.\n\nWork in progress\n\nTo enable access to recent NISV data we are working on connecting the latest version of the NISV catalogue to the Media Suite. As this is a very large data set we are still busy with the process of ingesting, indexing and testing.\nWe are preparing the digitized viewing figures data (Kijk- en Luistercijfers) to be added as a collection for the Media Suite \n\n",
        "url": "/documentation/release-notes/v4-10"
    },
    {
        "title": "Version 4.9",
        "text": "\nRelease notes V4.9 (09-03-2020)\nEnhancements\n\nSeveral bug fixes\nQuickly create a new project via the \"project selection widget\"\nChoose/create projects from the \"save query\" dialog (in the search tool)\nChoose/create projects from the \"bookmark\" dialog (in the search tool)\n\nNew features\nThe new resource viewer is there! It includes:\n\nAttractive design matching the workspace\nSeparate (hideable) column for displaying archival metadata\nSeparate (hideable) column for displaying \"content annotations\" such as speech transcripts and/or curated (program) segments\nSeparate (hideble) column for displaying your personal annotations\nWord cloud navigation for \"content annotations\": skip through AV content by clicking words in the cloud\nUI shows clear distinction between \"Resource\", \"Media Object\" and \"Segment\" level annotations\nFilters for showing/hiding the different annotation types: comments, codes, links or metadata (a.k.a. information cards)\n\nOther features:\n\nThe \"Empty field\" in each filter/facet block shows how many documents do not have a value filled in for the metadata field that underlies the filter.\nYou can now click on the individual years in the timeline graph to filter search results by that year\nIt's now possible to use the \"Compare queries\" tool via the workspace\n\nData improvements\n\nA new dataset with nature footage from Open Images was added\n\n",
        "url": "/documentation/release-notes/v4-9"
    },
    {
        "title": "Version 4.7",
        "text": "\nRelease notes V4.7 (20-01-2020)\nThe writing of these notes is still in progress\nBug fixing\n\n482: heavy facets\n532: bugs fixed in compare tool when deleting queries, improvements to the behavior of deleting queries\n476: consistent display of friendly labels in the Compare tool\n\nEnhancements\n\nSmall improvements to the Workspace forms and dialog boxes to create user projects and personal collections.\nissue/#496-update-workflow-for-items-bookmarking\ndate sorting in the workspace improved \nissue 476: User-friendly labels replaced technical labels shown when saving queries in the Search tool.\nissue 459: loading message for slow charts\nissue #545: shortcut to compare queries in the workspace (no need to open Compare tool)\nIssue/#476 beautify date field names (#510): more user friendly labels for date fields\n\nNew features\n\nMedia Type can be used now to filter in all collections\n(455) Improved selection options to search in all metadata fields and/or automatic enrichments\n(457) New tooltips with information added for date selection and filtering\n(#529) As a user, I want the MS to remember my selected collection across tools, just like the project \n\nData improvements\n\nAll collections include a curated date field (issue 31)\nNew ASR data (from the 1990's) -ask Johannes/Willem which data\n\n",
        "url": "/documentation/release-notes/v4-7"
    },
    {
        "title": "Version 4.4",
        "text": "\nRelease notes V4.4 (23-10-2019)\nBug fixing\nEnhancements\n\nSmall improvements to the Workspace forms and dialog boxes to create user projects and personal collections (see HowTos). \n\nNew data\n\nOne part of the oral history collection Verhalenhuis Belv\u00e9d\u00e8re has been made available in the Media Suite thanks to the collaboration between CLARIAH WP5 (especially Norah Karrouche, Max Broekehuizen, Roeland Ordelman) and DANS, from where the Media Suite harvests the metadata. Automatically-generated speech transcripts of 15 interviews were added. (Launched at the CLARIAH Oral History workshop).\n\n",
        "url": "/documentation/release-notes/v4-4"
    },
    {
        "title": "Version 4.3",
        "text": "\nRelease notes V4.3 (31-07-2019)\nBug fixing\n\nBugs have been fixed in the Compare, Inspect, and Search tool, and in the Workspace.\n\nEnhancements\n\nImprovements to the dialog boxes and interaction menu to save queries in the Search tool.\nImprovements to the highlight function, so it is easier for users to see the matching terms to their query highlighted in the results.\nUsability improvements in the Search tool.\n\nNew features\n\nCreate Custom Field cluster (users can select which fields they want to search in, and create their own clusters of fields).\nIt is possible to search for terms within the facets.\n\nData improvements\n\nThe workflow for adding metadata dictionaries via CKAN to the collections has been improved. It is now easier for collection owners to add and update metadata dictionaries.\nIn the Jupyter notebooks, and in the CKAN page for Oral history collections it is possible to query and visualize the oral history aggregated collection by the time period being discussed in the interviews.\nSmall improvements in the data (parsing, and cleaning date fields).\n\n",
        "url": "/documentation/release-notes/v4-3"
    },
    {
        "title": "Version 4",
        "text": "\nRelease notes V4 (03-04-2019)\nBug fixing\n\nFixes to the Compare tool (no more bug after selecting too many queries; no more weird behavior if queries have the same ID because of corrupt old data).\nRestyling of the query blocks in the Compare tool.\nBugs in the Inspector tool have been fixed.\n\nData enhancements\n\nThe collection pages have been enriched with visualizations, and the collection descriptions have been updated. \nIt is possible to access the collection pages from the Collection selector, Search, and Inspect tools.\nUser-friendly labels have been added to The Netherlands Institute for Sound and Vision (users can now use the user-friendly labels, but also are able to see the original name of the field when hovering the mouse over the labels).\nIn the resource viewer, it is possible to see and navigate through the curated segments from The Netherlands Institute for Sound and Vision collection (curated segments are parts of a program which have been selected and annotated more in detail by the archivists).\nNew functions have been added to the Jupyter notebooks.\n\nDocumentation\n\nNew section: HowTos.\nNew structure for easier navigation.\nA new consent form (privacy terms) has been added.\n\nStyling\n\nMajor improvements in the styling of the Tools page and Search tool.\nEnhanced pointers to the help menu from the tools.\n\n",
        "url": "/documentation/release-notes/v4"
    },
    {
        "title": "Version 3.2",
        "text": "\nRelease notes V3.2 (05-03-2019)\n\nTo be done\nthis is the pre-release, it includes all updates done since the last update on January 23, 2019\n\n",
        "url": "/documentation/release-notes/v3-2"
    },
    {
        "title": "Version 3.1",
        "text": "\nRelease notes V3.1 (23-01-2019)\nThis release includes mostly bug fixing and improvements based on regular testing, and from user input during the CLARIAH summer school and in the Gitter forum.\nOverall improvements\n\nThe main menu includes a new \"Learn menu\" where new content is progressively added)\nThe static pages of the Media Suite (About, Contact, Data, Tools) have been updated. \n\nBug fixing and (minor) usability enhancements\n\nIn the Inspector tool\nIn the Search tool (television collection, ordering per date is maintained after going back from exploring individual results)\nIn the Bookmarking functionalities\nIn resizing graphics\nMain bugs in the Workspace fixed (pending to solve ordering per creation date)\nBug when deleting annotations\n\nSystem overall improvements\n\nSecurity (now running on SSL, https, so your browser is happy!)\nRefurbishing of annotation API\nASR cloud infrastructure improved\nAutomatic testing\nStability improvements\n\nData improvements\n\nNEW collection: \u201cSound Bites\u201d collection of the Meertens Institute (read more: http://mediasuitedata.clariah.nl/dataset/soundbites).\nCollection selection and collection information (most pages in CKAN -http://mediasuite.clariah.nl/data include more complete information and visualizations)\n\nImprovements to data imports from:\n\nB&G: missing parts of records (from segments) were restored\nKB Newspapers (field names improved)\nKB Newspapers (better display of long titles)\nKB Newspapers (improved metadata display)\nNewly added metadata dictionary for the Desmet paper collection\nOral history: data cleaning to the import of the creator field\nASR on a new oral history collection, \u201cverhalenhuis\u201d (more information forthcoming)\n\nTools functionalities and front-end (UI) improvement\nCollection selector and data pages (CKAN)\n\nIt is possible to navigate to collection pages from the tools (when selecting a collection, and when searching or inspecting a collection)\n\nInspector tool \n\nA new graphic type for easier completeness visualisation was added\nCompleteness display improved\n\nSearch tool \n\nNew cluster (keywords for all collections) and field cluster menu improved\nFacet selector improved (negative facet selection, select more than one facet, ordering options for terms in facets)\nBookmarking facilities improved: bookmark across pages, bookmark across collections, pre-selection list (to check before saving)\n\nCompare tool \n\nAdjustments after the initial release of the renewed Compare tool, which was redesigned to work with user \u201csaved queries\u201d\n\nResource viewer \n\nWe added a feature that facilitates exploration of related content based on the keyword fields\nResearch is being done to improve the Resource viewer in the future\n\nWorkspace (small improvements)\n\nCopy saved query parameters to clipboard\nAccess icons that indicate if an item can be viewed or not can be used for filtering\nMedia type icons that indicate the type of media can be used for filtering\nImproved ordering options\n\nDocumentation and tooltips\n\nDocumentation pages styling and internal update workflow via Github improved\nDocumentation pages are fully integrated in the Media Suite\n  Informative messages were added when there are known issues in searching or filtering\nUpdated documentation pages (in progress during January-February, 2019)\n\nForthcoming: \n\nUpdated screencasts\nNew content: Research projects\nNew content: Quick start guide\n\n",
        "url": "/documentation/release-notes/v3-1"
    },
    {
        "title": "Version 3",
        "text": "\nRelease notes V3 (06-20-2018)\nVersion 3 of the Media Suite has new data, bug fixes and many new features!:\nNew data\nASR\nA significant portion of the collections of The Netherlands Institute for Sound and Vision is automatically annotated using automatic speech recognition processes (ASR), resulting in verbatim transcripts available for search and interactive navigation of the resources. The automatic annotation process is still ongoing. In Version 3 transcripts are available for:\n\nRadio 1 (Hilversum 1, NPO Radio 1): more than 90%\nRadio 5 (747 AM, NPO Radio 5): more than 60%\nSource catalogs (items from the Radio Programma, Weken Nederlandse Radio, and Hoorspelen  collections): more than 40%\nTelevision (news and current affairs): about 25%\n\nMore information here.\nEYE Jean Desmet\nWe added new collections and increased access to resources from collections from EYE Film Museum:\n\nThe Jean Desmet business (paper) archive has been made fully available for browsing (according to the same archival structure provided by EYE).\nThe Desmet business (paper) archive can also be searched, thanks to experiments with OCR-ing this collection. The OCR allows for searching the full text of the typed written documents. Other automatic detection experiments allow to group items per type (e.g., letters, telegrams, etc.), logos, signatures, languages, among others.  See more information about how this collection was made available in the Media Suite data registration system. <>http://mediasuitedata.clariah.nl/dataset/desmet-paper-collection.\nViewing of the +100.000 digitized images is possible via a IIIF server.\nThose images can be annotated.\nThe Desmet film collection, which metadata was made available in Version 2 of the Media Suite linking to the publicly accessible Youtube videos, is now fully available for viewing, more than eight hundred films can be played from the EYE servers via the Media Suite (available from July 2, 2018).\n\nOral history interviews (open access available)\n\nThe \"open/open access\" oral history interviews at DANS can be now played and annotated via the Media Suite.\n\nImprovements to Beeld en Geluid Audio-visual collection\n\nThere were improvements to the data completeness of The Netherlands Institute of Sound and Vision after detailed data integrity checks.\n\nKB newspapers\n\nThe index of the KB newspaper basic collection is fully completed (available for search from July 2, 2018)\n\nTools improvement\n\nThe Inspector tool has been redesigned and improved with \"metadata dictionaries\".\nWe redesigned the Compare tool to work with the newly implemented Saved queries.\nWe fixed a number of bugs in the Search tool. We also added new features that were requested by the main users (researchers) to all tools. These include:\nImproved faceted search (full term view, filtering, and download)\nSaved queries\nImprovements to the timeline charts and histograms\nImprovements to the Bookmarking facilities\nIn the browsing tool (\"Explore\") we made possible to connect the resources to the Workspace functionalities. Users can now add bookmarks and annotate resources from the Explore tool, save \"Tool sessions,\" and find all these in their Workspace.\nThe browsing tool (\"Explore\"), new functionalities were added to facilitate adding comments to \"Browsing paths.\"\n\nWorkspace (second version)\nWe improved significantly the \u201cWorkspace,\u201d which first version was launched in the previous release of the Media Suite:\n\n\nAll views (bookmarks, codes, comments, links, metadata cards) were split for improving clarity\n\n\nEach view was improved with filtering options\n\n\nViewing and exporting user fragments became more clear\n\n\nUsers can add personal collections to their work space, these collections can be searched and annotated (ASR for personal collections is forthcoming).\n\n\nWe added experimental Jupyter notebooks to allow python skillful users to work with the Media Suite data\n\n\nAnd more...\n\nWe improved interface and interaction.\nThe Documentation pages and blog in Github pages have been fully updated.\nSignificant back-end improvements.\n\n",
        "url": "/documentation/release-notes/v3"
    },
    {
        "title": "Version 2.1",
        "text": "\nRelease notes V2.1 (01-25-2018)\nThis version has improved bookmarking functionalities and more:\n\nWe added functionality for bookmarking multiple search results from the single search page\nYou can now organize your bookmarks by arranging them in different lists within your project (viewable in your workspace)\nEach search result now includes media type & accessibility information\nThe Beeld en Geluid collection by default now shows much more genres in the \"genre facet\", since it is now tied to the \"series level\" metadata, instead of the \"program level\" metadata\nMiscellaneous small updates to the user interface\n\n",
        "url": "/documentation/release-notes/v2-1"
    },
    {
        "title": "Version 2",
        "text": "\nRelease notes V2 (12-20-2017)\nVersion 2 of the Media Suite has new data, bug fixes and new features. Overview:\n\nWe added datasets/collections from The National Library of The Netherlands (KB), EYE Film Museum, and DANS.\nIn the tools, we fixed a number of bugs. We also added new features that were requested by the main users (researchers).\nWe implemented a \u201cWorkspace\u201d so that you can store and retrieve your bookmarks your annotations and track your research in the Media Suite.\nWe did a redesign of the interface and interaction featuring new styling and a more natural flow\nWe set up the Documentation pages and blog in Github pages to facilitate later updates.\n\nSee the full list of changes below: \nData integration:\n\nKB newspaper collection: The newspaper collection of the National Library of The Netherlands has been harvested and indexed in the Media Suite. We provide access to the data before 1945 in the first import (these data is expected to be completed to cover the entire KB dataset in the subsequent improvements of version 2).\nEYE Desmet collection: The full metadata from two of the five subsets of the EYE\u2019s Desmet Collection have been added (i.e., the film and poster collections). Access/viewing of some of the films and posters is also possible. The two datasets have been connected when the data was available (e.g., the film records include links to the posters when these are available). Disclaimer: the date fields of the Desmet datasets from EYE include non-normalized data (e.g., 1916 (gewijzigde versie), 1912 (1911 volgens Langman). This is a normal situation in archival metdata. The cleaning of these data will be done for a subsequent release to this version. In version 2, these two datasets cannot be inspected in the Media Suite, but they can be searched and compared.\nDANS Oral history collections: The metadata from sixty four thematic collections and projects has been automatically harvested from the OAI-PMH endpoint of DANS, and indexed in the Media Suite. This does not include the speech recognition transcripts yet. Access to the content (play-out) is not possible yet.\n\nMajor fixes and new features in the tools:\n\nGeneral improvements to the query builder: In the search and compare tools, bugs with date selections have been solved, time slider for selecting dates has been changed to date picker, Boolean queries are enabled, field clusters to the Sound and Vision Collection have been added.\nGeneral improvements to the results and result list: In the search and compare tools issues with display of titles and dates have been solved, basic statistics of results per collection have been added, tooltips have been included, the resource viewer has been splitted into summary view and detailed view.\nGeneral improvements to the graphics/visualizations: The main bugs and issues with timeline chart and histogram in the Collection Inspector and Search and Compare tools have been solved. The dynamics of the time-line chart has been improved, the histogram is located in a more visible place, absolute values from results in a given point of time have been added to the graphics.\nFixes and new features in the Collection inspector tool: Bugs in the calculations have been fixed, statistics presentation has been made more transparent, issues with dates in the date field axis of the timeline chart have been fixed, the syntax and grouping of the metadata fields and their types has been made more user-friendly, a search box for metadata fields has been added for string search.\nFixes and new features in the Search tool: Collections can be added directly from this tool.\nImprovements to the annotation tool: Display of titles for segments has been improved, new option to add custom links.\nFixes and new features in the Exploratory browser: The four datasets (Tropenmuseum, KB news bulletins, Amsterdam Museum and OpenImages) in the new version remain unchanged with respect to previous versions of the exploratory browser. Changes include updated event labels for the news bulletins, based on extraction work by Kim Bosman. Additional events have been extracted for the Tropenmuseum data based on work by Victor Kramer. Furthermore, provenance and license information has been added for media objects as well as for metadata triples (named graphs). Filtering in the DIVE browser has been improved. Note: the integration of this browser in the linked data/tools workflow of the Media Suite will be included in Version 3 and 4.\n\nNEW! Workspace\n\nOption to create user projects: You can create your own projects and store bookmarks, annotations, and search sessions. These projects can be private or public (other users can see the data stored by the individual users in a project)\nBookmarking resources and adding them to projects: Each individual result can be bookmarked and added to a user project from the resource viewer.\nSaving tool sessions: We are working on a feature that enables you to store a tool session, including its queries and filter settings. The Media Suite is already able to display this data.\nImplementing this feature in the tools is planned for next year. Currently there is an example DIVE+ tool session, that demonstrates this feature.\nViewing user projects: All user projects per user, and public projects can be viewed in a list, opened, and exported.\nViewing user bookmarks and annotations: All aggregated bookmarks and annotations added by a user can be viewed in two ways: a list of bookmarks with annotations, or a list of aggregated annotations with links to the items they correspond to.\nExporting user projects, bookmarks and annotations: All data in the work space can be exported to a JSON file.\n\nMajor styling and design\nDuring the last three months of 2017 we worked on improving the styling of the Media Suite user interface and the design of the workspace. This resulted in a new design, that includes:\n\nInclusion of (styled) new features that support scholars in all research phases, including brand new Workspace features!\nImproved user flow that supports easy navigation between Data, Tools and Workspace.\nConsistent styling that makes the UI more user friendly and gives it a recognizable and professional look and feel.\n\nA lot of invisible/back-end work:\nThe development team made significant progress in building the Media Suite with an infrastructural approach, this means that there has been a lot of effort put into servers\u2019 maintenance, such as: the semi-automatic process for the deployment of the entire infrastructure (for both a test and production environment), versioning control, backups of data & virtual servers; a scaled up data cluster; security of APIs & video play-out; enhancements of the annotation model & functionalities are amongst many others...\nNote: Release of Version 3 is planned for April 2018 with possibly some smaller updates in between.\n",
        "url": "/documentation/release-notes/v2"
    },
    {
        "title": "Version 1",
        "text": "\nRelease notes V1 (04-04-2017)\nFirst version of the \"Recipes,\" \"Components,\" \"Data,\" and \"APIs.\"\n(More information to be added soon).\n",
        "url": "/documentation/release-notes/v1"
    },
    {
        "title": "GLOSSARY",
        "text": "\nGlossary\nThis section includes basic definitions of terms that may be unfamiliar for either developers or scholars.\n",
        "url": "/documentation/glossary"
    },
    {
        "title": "Alignment",
        "text": "\nAlignment\nBy Roeland Ordelman\nAlignment (officially \u2018forced alignment\u2019) is the process of  synchronizing a text transcription of speech to the audio recording that  contains the speech, by automatically adding time labels to every word  in the transcript using a specific form of speech recognition  technology. This technology is sometimes called \u2018informed speech  recognition\u2019: the words to be recognized are already known \u2014 the task is  to find the exact positions in the audio where the words occur. In  practice, the speech transcripts are usually not an exact representation  of the speech. For example, repetitions and filler words such as \u2018uh\u2019  and \u2018ah\u2019 are often omitted, and ungrammatical sentences reformulated.  The further the text transcripts depart from the verbatim speech, the  more difficult the alignment process for the speech recognition  technology will be.\nAlignment is a very valuable tool to enable word level access to  spoken word recordings (jump to positions where a particular word is  mentioned) in cases where text transcripts are available such as in Oral  History research where scholars are used to making verbatim transcripts  of interviews in word processors that do not capture time information.   Examples of text transcripts in other domains that are deployed for  alignment are subtitles for the hearing impaired, auto-cues, production  scripts, and court reports.\nAn alignment tool typically takes as input (i) a plain text file with  the speech transcript, and (ii) the audio recording that contains the  speech, and provides as output a file where time labels are added to  each of the words in the transcript, for example in a list format with  on each line the start time and a word:\n00:01:23:34 today\n00:01:25:01  we\n00:01:25:28 started\nThis output can be used in a transcription viewer to  jump  immediately to the corresponding position in the audio file by clicking  on a word while viewing a single interview. It can also be used to jump  to positions in multiple audio files by indexing the aligned text (of  multiple interviews) in a search engine.\nSee more at this blog post about the CLARIN-Plus workshop on oral history.\n",
        "url": "/documentation/glossary/alignment"
    },
    {
        "title": "API",
        "text": "\nAPI\nApplication programming interface. A set of subroutine definitions, protocols, and tools for building application software; makes it easier to develop a computer program by providing all the building blocks, which are then put together by the programmer. \nSource: Wikipedia.\nSee information about the Media Suite APIs.\n",
        "url": "/documentation/glossary/api"
    },
    {
        "title": "Elastic search",
        "text": "\nElastic Search\nElasticsearch is a search engine based on Lucene. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents. Elasticsearch is developed in Java and is released as open source under the terms of the Apache License.\nSource: Wikipedia\n",
        "url": "/documentation/glossary/elastic-search"
    },
    {
        "title": "JSON",
        "text": "\nJSON\nJSON\u00a0(JavaScript Object Notation) format, which is a ubiquitous internet data interchange format.\n",
        "url": "/documentation/glossary/json"
    },
    {
        "title": "OAI-PMH",
        "text": "\nOAI-PMH\nThe Open Archives Initiative Protocol for Metadata Harvesting (OAI-PMH) is a low-barrier mechanism for repository interoperability. Data Providers are repositories that expose structured metadata via OAI-PMH. Service Providers then make OAI-PMH service requests to harvest that metadata. OAI-PMH is a set of six verbs or services that are invoked within HTTP. \nSource: OAI-PMH website\n",
        "url": "/documentation/glossary/oaipmh"
    },
    {
        "title": "Research Data Management",
        "text": "\nResearch Data Management\nResearch data management (RDM) is an important topic for researchers nowadays. For their research, scholars are required to develop a research data management plan that helps them to make conscious decisions about research data and keeps data safe. This is particularly important when working with personal data. Research data management also encourages open science and enables the reuse of data which is evidently very important in the context of research infrastructures, such as CLARIAH. Archiving research data is the best way to guarantee scientific integrity and enable verification and potential reuse of datasets. Typically, data is archived at publication or after research via a certified archive.\nIn the Media Suite, researchers can be provided access to collections as long as privacy criteria are met. This may be different for each collection. For some collections, it may be the case that access needs to be requested on an individual basis, either via the archive that maintains the collection (e.g., DANS) or via the researcher that created the collection. CLARIAH is developing methods to first of all, make access restrictions for collections transparent, and secondly, enable online processing of requests and permissions. The first step we are taking is setting up a CLARIAH-wide authentication and authorization system that would allow us to authorize the use of collections to specific scholars that are authenticated by the system.\n",
        "url": "/documentation/glossary/rdm"
    },
    {
        "title": "Transcription",
        "text": "\nTranscription\nBy Roeland Ordelman\nTranscription is the systematic representation in written form of  language: speech, sign language, or text in another writing form. In the  academic discipline of Oral History research, transcription is an  essential part of the methodology, as the transcripts are the main  source for analysis of the Oral History interviews. In recent times,  tools such as alignment are emerging that allow Oral History scholars to  simultaneously use text transcripts and the original audio recordings  during analysis. Outside academia, examples of transcriptions are the  proceedings of court hearings or physician\u2019s recorded voice notes. A  verbatim transcript includes all dialogue spoken, word for word,  including fillers, false starts, and repetitions.\nAutomatic speech recognition (ASR) technology is increasingly used to  support or even replace manual transcription. As speech recognition  will produce errors that need to be corrected manually afterward,  specialized tools are developed that try to make the correction work  less tedious.\nSee more at this blog post about the CLARIN-Plus workshop on oral history.\n",
        "url": "/documentation/glossary/transcription"
    },
    {
        "title": "Trove",
        "text": "\nTrove\n\"TROVe stelt wetenschappers in staat stelt om de verspreiding van nieuws, opinie en debat  te analyseren in verschillende media door de tijd heen. Hiermee kunnen de bijdragen van en onderlinge relaties tussen massamedia en nieuwe (sociale) media onderzocht worden. TROVe geeft inzicht in de manieren waarop media, informatie en individuen het digitale tijdperk verbonden zijn, hoe zij het publieke debat bepalen, en hoe zijn erdoor bepaald worden. Helaas is TROVe vanwege rechten- en serverbeperkingen niet meer beschikbaar tot aan zijn integratie in de Media Suite. Bekijk hier wel de screencast uit 2013.\"\nMore information about TROVe here.\nNote: This tool is not maintained as such by CLARIAH. Instead, extended collections and functionalities can be used via the Media Suite.\n",
        "url": "/documentation/glossary/trove"
    },
    {
        "title": "User project",
        "text": "\nUser project\nIn the Media Suite, a \"User project\" is defined as a sort of container for storing personal corpora and annotations created during search and analysis of the data available in the Media Suite.  Some of the Qualitative Data Analysis (QDA) typically used by researchers, refer to user projects as \"hermeneutic units\" (in Atlas.ti) or \"Projects\" (in NVIVO). \nIn the Media Suite, for instance, a researcher can create a user project for a topic or for a research question, which will help her/him, among others, to:\n\nGroup together entire items or fragments for creating a corpus (the so-called \"bookmarks\"), \nAdd and retrieve manual annotations\nStore and compare saved queries\nKeep track of her/his browsing history (the so-called \"navigation paths\" in the Exploratory tool)\nTake screenshots of \"tool sessions\" (in Version 4 only available in the Exploratory tool).\n\nSee also the sections on how to work with User projects.\nIf you have any questions, please contact us.\n",
        "url": "/documentation/glossary/user-project"
    },
    {
        "title": "Verteld Verleden",
        "text": "\nVerteld Verleden\n[Dutch text] \"Verteld Verleden brengt (meta)data en spraaktranscripten van tientallen oral history-collecties verspreid over Nederland bij elkaar en maakt deze doorzoekbaar op basis van gedetailleerde zoek- en filteropties. De tool bevordert daarmee de toegankelijkheid en doorzoekbaarheid van deze unieke collecties. Geen inloggegevens vereist.\"\nVerteld Verleden is one of the \"seed projects\" of the CLARIAH Media Suite (see FAQ: How is the CLARIAH Media Suite being built? The tool was developed in a previous oral history project and is no maintained as such by CLARIAH. Instead, extended collections and functionalities can be used via the Media Suite.\nExtra information\nThe Oral History project \u2018Verteld Verleden\u2019 (Dutch literal translation of Oral History), focuses on improving access to spoken testimonies in collections, spread over many Dutch cultural heritage institutions, by deploying modern technology both concerning infrastructure and access. Key objective in the project is mapping the various specific requirements of collection owners and researchers regarding both publishing and access by means of current state-of-the-technology. In order to demonstrate the potential, Verteld Verleden develops an Oral History portal that provides access to distributed collections. At the same time, practical step-by-step plans are provided to get to work with modern access technologies. In this way, a solid starting point for sustained access to Oral History collections can be established.\nTechnology and daily practice\nThe Verteld Verleden project builds upon years of academic research on access technology for spoken word archives [1,2,3] deploying among others automatic speech recognition, text-to-speech synchronization and fragment-level search. This research resulted in a number of demonstration applications in close cooperation with cultural heritage institutes [4,5,6]. Although these demonstrations have been very well received both by the public and involved institutes, it was observed that there is still a gap between academic, \u2018technology-driven\u2019 pilots and the daily practice of Dutch cultural heritage institutions and researchers. One important observation was that Oral History collections are managed in many different ways: from very adequate to not at all. There are a few \u2018forerunners\u2019 that do already make use of various professional infrastructures and technologies for disclosure and access but the larger part of the collection owners, in spite of acknowledging the virtues of modern access technologies, often do not have the knowledge or means to really start using these. In practice, access to Oral History collections in general is very limited and publically accessible overviews on available collections are missing. On the other hand, we see that collection owners and researchers have very specific requirements with regard to management, disclosure and access, and have very detailed knowledge of their collections and their contexts.\nKnowledge transfer\nIn order to be able to catch up with the advantages of the digital networked society, cultural heritage institutes need practical handles that are specifically geared towards their specific use cases. The Verteld Verleden project follows this practical approach by mapping the available solutions and best practices in The Netherlands on a diversity of relevant topics ranging from digitization of audio-visual data, format conversion, online access to collections, and  (semi)automatic metadata generation, and linking collections to other information sources, to dealing with privacy/copyright issues. On an academic level, special attention is addressed towards transfer of knowledge and awareness on methodology and theory of Oral History research, and the design of Oral History research in combination with modern technology.\nShowcase\nTo showcase how these best-practices and solutions could work out in practice the project builds an embeddable Oral History portal that enables access to distributed oral history collections. The general approach is that collections owners are urged to comply with interoperability standards on the dissemination of metadata and content. By adopting these standards, content owners allow aggregators to channel content into local portals (e.g., Verteld Verleden) or even international portals such as the Europeana portal [9]. The Verteld Verleden portal serves here as a so called thematic portal.\nVerteld Verleden promotes OAI-PMH, the Protocol for Metadata Harvesting and stimulates content owners to have their content available using a streaming media protocol to enable play-out of search results. The Verteld Verleden portal harvests metadata from associated institutes and provides centralized search for searching and browsing the collections that are linked up. As the portal\u2019s user interface can also be embedded in the local websites, content owners can be provided with search functionality for their own content.\nState-of-the-art\nThe portal is equipped with state-of-the-art search technology and a flexible user interface that allows the project to adapt it easily to the requirements of researchers and content owners that are expected to advance during the project as a result of discussions at workshops and local expert sessions. An important requirement of researchers is evidently to have sophisticated means to access and analyse available Oral History collections.  To a large extent however, access to collections is rather limited due to the lack of appropriate fragment-level semantic descriptions. Metadata is often only sparsely available, forcing scholars to play an A/V item in full in order to decide if, and if so, which parts of the material are of interest for their research. Moreover, exploring possible correlations and connections both within and across large data collections requires an additional layer on top of the metadata for the interlinking of multimedia content sources and/or collection fragments. Ultimately, also dedicated technology for browsing, accessing, analysing and comparing sources effectively during the various phases of research (exploration, analysis, publication, verification) are a prerequisite for the innovation of the methodological framework of humanities researchers and for the formulation of new questions and the renewal of research agendas. In order to successfully exploit these technologies for the purpose of humanities research, their development must strongly be steered by the demands and requisites of the researchers and their research paradigms.\nSpeech Recognition\nA special role in the project is assigned to the use of speech recognition technology. Speech recognition can play an important role in the process of making Oral History content better accessible, either directly via the conversion of speech to text or indirectly using available textual transcripts and a technology derived from speech recognition often referred to as forced-alignment.  Verteld Verleden offers associated content owners the use of a speech recognition service supported by the Dutch CATCHPlus program [10], that aims to valorise scientific research results to usable tools and services for the Entire Dutch heritage sector.\nDeploying speech recognition brings up an additional challenge with regard to metadata models and harvesting standards: it encompasses the need to incorporate time-labelled into the metadata model. Approaches are currently investigated in close collaboration with CLARIN-NL, a project on Common Language Resources and Technology Infrastructure [7].\nReferences\n[1] Goldman, J., Renals, S., Bird, S., de Jong, F. M. G., Federico, M., Fleischhauer, C.,\nKornbluh, M., Lamel, L., Oard, D. W., Stewart, C., & Wright, R. (2005). Accessing the spoken word. Int. Journal on Digital Libraries, 5(4), 287\u2013298\n[2] F.M.G. de Jong, D.W. Oard, W.F.L. Heeren and R.J.F. Ordelman Access to recorded interviews: A research agenda, ACM Journal on Computing and Cultural Heritage (JOCCH), 1(1):3-29, ISSN 1556-4673, 2008\n[3] R.J.F. Ordelman,  W.F.L. Heeren, M.A.H. Huijbregts, F.M.G. de Jong and D. Hiemstra Towards Affordable Disclosure of Spoken Heritage Archives, Journal of Digital Information, M.A. Larson, K. Fernie and J. Oomen (eds), 10(6):17-33, ISSN 1368-7506, 2009\n[4] Radio Oranje Demonstrator (alignment of historical speeches): http://hmi.ewi.utwente.nl/choral/radiooranje.html\n[5] Searching interviews bombarding of Rotterdam: http://www.gemeentearchief.rotterdam.nl/brandgrens/navigator/interviews.php\n[6] Access to interviews with survivors of World War II concentration camp Buchenwald: http://www.buchenwald.nl\n[7] CLARIN-NL: http://www.clarin.nl\n[8] Verteld Verleden homepage: http://www.verteldverleden.org\n[9] Europeana portal: http://www.europeana.eu/portal/\n[10] OAI-PMH: http://www.openarchives.org/pmh\n[11]  CATCHPlus program: http://www.catchplus.nl/en/\n",
        "url": "/documentation/glossary/verteld-verleden"
    },
    {
        "title": "Terms of use and privacy",
        "text": "\nTerms of use and privacy\n1. Use of copyright protected data\nThe CLARIAH Media Suite contains material that is under copyright protection. It is therefore expressly forbidden to take this material out of the Media Suite environment, regardless in what form, for example by downloading material or by making a screenshot (photo of the screen) or screencast (film of the screen), without the express permission of the rightsholder.\n\n2. Privacy\nWe, the Netherlands Institute for Sound and Vision, process personal data belonging to our (website) visitors and clients. We do this in order to help our visitors and clients as best possible, and to achieve our strategic goals. In this privacy statement we explain why, and in what way, we process your personal data.\nWho are we?\nThe Netherlands Institute for Sound and Vision is the tradename of the Foundation Netherlands Institute for Sound and Vision. We are located at Media Parkboulevard 1 (1217 WE), in Hilversum. We are registered in the Chamber of Commerce under the registration number 41194855. Your details are handled carefully and protected satisfactorily. We do so in accordance with the General Data Protection Regulation (GDPR) and other applicable regulations.\nHow do we collect personal data?\nWe get the personal data that we process on our website visitors from our identity providers when you log in on our website. You can find a list of all identity providers here.\nDo we also use cookies?\nSound and Vision uses cookies. A cookie is a small file that we send with the webpage, and that your browser stores on your computer. For example, we use cookies to analyse how the website is used, and to remember settings and preferences when you visit our site.\nWhy do we store cookies?\nWe use cookies to optimise the functioning of our website, and to offer you a better visitor experience.\nThere are different sorts of cookies:\n1. Functional cookies\nThis site stores cookies on your computer that are related to the functioning of the website. The aim of these cookies is to optimise the user experience by storing your preferences. In no way do these cookies store sensitive data. According to the current cookie regulations, they may be stored without permission.\n2. Analytical cookies\nWe store analytical cookies from Matomo on your device. We use these cookies to register which pages you visit, whether you have visited them before, and, for example, which device and browser you use to do this. In this way, we can offer you the best experience when you are searching for information on our website. This data is anonymous, and is not linked to your name, address, email address or other personal data. Your IP address is also anonymised.\nWhich data do we process?\nWe process the following personal data from our website users, in so far as we receive this from the identity providers:\n\nname, (email) address\nIP address\ndetails of the group you belong to (e.g. employees or students) and your position.\n\nIn addition to this, we process personal data belonging to the persons who appear in the archive material that is offered on our website. In principle, these can be all types of personal data, including special categories of personal data.\nWhat do we process this data for?\nWe process your personal data for the following purposes:\n\nTo provide archive material to researchers: if you are logged in, then you can access archive material.\nTo improve our services and bring them to people's attention.\n\nOn what basis do we use the personal data?\nOur processing of your personal data for the above-mentioned purposes has the following legal basis:\n\ncarrying out the agreement(s) regarding the provision of various functionalities for the purpose of making archive material available.\nthe legitimate marketing and research interest that we have in improving and drawing attention to our Media Suite service.\n\nHow long do we store your data?\nWe don\u2019t store your data for longer than is lawfully permitted, lawfully required and/or necessary for the purposes for which the details are processed. How long certain data are stored is therefore dependent on the nature of the data and the purpose for which they are processed. The storage period can therefore vary per purpose.\nIs your data shared with other parties?\nNO, your data is not shared with other parties.\nHow is my data protected?\nWe have taken appropriate technological and organisational steps to protect your data against loss and against use contrary to the rules. We constantly keep up to date with the current situation regarding technological protection of personal data and will do everything possible to prevent the loss or unlawful use of personal data. We do our very best to protect ourselves against the activities of 'hackers'. However, we cannot guarantee this protection, due to continual technological advances.\nYour rights\nYou have a number of rights. These are:\n\nRight of access and to be informed: you can ask us which details of yours we have and use. We will then gladly tell you more about how and why.\nRight to rectification: do you think we have incorrect details about you? Let us know, then we will correct them.\nRight to erasure: you can request us to remove the data belong to you that we have and use. In most cases we will comply with this request, but it is possible that we still need to process the details for other purposes (e.g. administration).\nRight to restrict processing: if you think that we are unlawfully or incorrectly processing your data, then you can ask us to stop using your data until we can sort it out.\nRight to object: You can object to the use or storage of your data. We will then see if we can stop processing, or delete your data. Do you object to the use of your data for marketing purposes? Then we will stop the processing as soon as possible.\nRight to data portability: You can request us to hand over the data we process on your behalf.\n\nIn addition, you can also:\n\nSubmit a complaint to the Dutch Data Protection Authority (DPA): Do you think we are not acting in accordance with the rules? Then please let us know. You can also submit a complaint about this to the DPA.\n\nWhere can I go with my questions?\nIf you have questions about our processing of your personal data, or if you want to make use of one or more of your legal rights, then contact:\n\nOur privacy officer, who is available via: Webmaster\n\n",
        "url": "/documentation/privacy-statement"
    }
]};
